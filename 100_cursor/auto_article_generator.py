#!/usr/bin/env python3
"""
è‡ªå‹•è¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
ã‚¯ãƒªãƒƒãƒ—ã‹ã‚‰è¨˜äº‹ã¾ã§å®Œå…¨è‡ªå‹•åŒ–
"""

from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

from base_processor import BaseProcessor
from utils import (
    extract_metadata_from_content,
    extract_sections,
    clean_filename,
    determine_category,
    run_python_script,
    create_unique_filename
)
from config import VAULT_PATH, INSIGHT_KEYWORDS


class AutoArticleGenerator(BaseProcessor):
    def __init__(self, vault_path: str):
        super().__init__(vault_path, 'auto_article_generator')
    
    def process_clip_to_literature(self) -> List[Path]:
        """Step 1: Clipã‚’Literatureã«å‡¦ç†"""
        self.log_info("Step 1: Processing clips to Literature")
        
        # process_clip.pyã‚’å®Ÿè¡Œ
        script_path = self.cursor_dir / 'process_clip.py'
        success, stdout, stderr = run_python_script(script_path, self.vault_path)
        
        if success:
            self.log_info("Clips processed successfully")
            # å‡¦ç†ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—
            return self.get_recent_files(self.literature)
        else:
            self.log_error(f"Failed to process clips: {stderr}")
            return []
    
    
    def extract_key_insights(self, file_path: Path) -> Dict[str, any]:
        """Step 2: Literatureã‹ã‚‰é‡è¦ãªæ´å¯Ÿã‚’æŠ½å‡º"""
        self.log_info(f"Step 2: Extracting insights from {file_path}")
        
        content = self.read_file_safe(file_path)
        if not content:
            return None
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        metadata = extract_metadata_from_content(content)
        
        # ä¸»è¦ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡º
        main_points = extract_sections(content, "ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ")
        
        # æ´»ç”¨ä¾‹ã‚’æŠ½å‡º
        use_cases = extract_sections(content, "æ´»ç”¨ä¾‹")
        
        # æ´å¯Ÿã‚’ç”Ÿæˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯AI APIã‚’ä½¿ç”¨æ¨å¥¨ï¼‰
        insights = self._generate_insights(content, main_points, use_cases)
        
        return {
            'file_path': file_path,
            'metadata': metadata,
            'main_points': main_points,
            'use_cases': use_cases,
            'insights': insights,
            'original_content': content
        }
    
    
    def _generate_insights(self, content: str, main_points: List[str], use_cases: List[str]) -> List[str]:
        """æ´å¯Ÿã‚’ç”Ÿæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        insights = []
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“åˆ†æ
        content_lower = content.lower()
        for keyword, insight_template in INSIGHT_KEYWORDS.items():
            if keyword.lower() in content_lower:
                insights.append(f"{insight_template}ãŒç¤ºå”†ã•ã‚Œã‚‹")
        
        # ä¸»è¦ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰æ´å¯Ÿã‚’ç”Ÿæˆ
        if len(main_points) > 3:
            insights.append("å¤šé¢çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ãªè¤‡é›‘ãªãƒˆãƒ”ãƒƒã‚¯")
        
        # æ´»ç”¨ä¾‹ã‹ã‚‰æ´å¯Ÿã‚’ç”Ÿæˆ
        if use_cases:
            insights.append(f"{len(use_cases)}ã¤ã®å…·ä½“çš„ãªæ´»ç”¨æ–¹æ³•ãŒå­˜åœ¨")
        
        return insights[:3]  # ä¸Šä½3ã¤ã®æ´å¯Ÿ
    
    def create_permanent_note(self, literature_data: Dict[str, any]) -> Tuple[Optional[Path], Optional[str]]:
        """Step 3: Permanentãƒãƒ¼ãƒˆã‚’ä½œæˆ"""
        self.log_info("Step 3: Creating Permanent note")
        
        # ã‚«ãƒ†ã‚´ãƒªã‚’æ±ºå®š
        category = determine_category(
            literature_data['original_content'],
            literature_data['metadata'].get('tags', [])
        )
        
        # Permanentãƒãƒ¼ãƒˆã®å†…å®¹ã‚’ç”Ÿæˆ
        permanent_content = self._generate_permanent_content(literature_data)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
        title_clean = clean_filename(literature_data['metadata'].get('title', 'Untitled'))
        base_filename = f"{title_clean}_æ´å¯Ÿ"
        file_path = create_unique_filename(self.permanent / category, base_filename)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        if self.write_file_safe(file_path, permanent_content):
            self.log_info(f"Permanent note created: {file_path}")
            return file_path, permanent_content
        else:
            return None, None
    
    
    def _generate_permanent_content(self, literature_data: Dict[str, any]) -> str:
        """Permanentãƒãƒ¼ãƒˆã®å†…å®¹ã‚’ç”Ÿæˆ"""
        metadata = literature_data['metadata']
        insights = literature_data['insights']
        main_points = literature_data['main_points']
        
        content = f"""# {metadata.get('title', 'Untitled')}ã®æ´å¯Ÿ

## æ¦‚è¦
{metadata.get('title', '')}ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸçŸ¥è­˜ã‚’è‡ªåˆ†ã®è¨€è‘‰ã§å†æ§‹ç¯‰ã—ãŸãƒãƒ¼ãƒˆã€‚

## æ ¸å¿ƒæ¦‚å¿µ

### ä¸»è¦ãªæ´å¯Ÿ
"""
        
        for insight in insights:
            content += f"- {insight}\n"
        
        content += """

### å®Ÿè·µã¸ã®å¿œç”¨
"""
        
        for i, point in enumerate(main_points[:3], 1):
            content += f"{i}. {point}\n"
        
        content += f"""

## é–¢é€£ã™ã‚‹æ¦‚å¿µ
- [[{metadata.get('title', 'Original')}]] - å…ƒã®Literatureãƒãƒ¼ãƒˆ

## ä»Šå¾Œã®å±•é–‹
ã“ã®æ´å¯Ÿã‚’åŸºã«ã€å®Ÿè·µçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¤œè¨ã—ã€å…·ä½“çš„ãªè¡Œå‹•è¨ˆç”»ã‚’ç«‹ã¦ã‚‹ã€‚

---

**ä½œæˆæ—¥**: {self.format_timestamp('%Y-%m-%d')}  
**ã‚¿ã‚°**: #permanent {' '.join(metadata.get('tags', []))}  
**å‚è€ƒæ–‡çŒ®**: [[{Path(literature_data['file_path']).stem}]]
"""
        
        return content
    
    def create_article(self, permanent_data: Dict[str, any], literature_data: Dict[str, any]) -> Optional[Path]:
        """Step 4: è¨˜äº‹ã‚’ç”Ÿæˆ"""
        self.log_info("Step 4: Creating article")
        
        # è¨˜äº‹ã®å†…å®¹ã‚’ç”Ÿæˆ
        article_content = self._generate_article_content(permanent_data, literature_data)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
        date_prefix = self.format_timestamp('%Y%m%d')
        title = literature_data['metadata'].get('title', 'Untitled')
        title_clean = clean_filename(title)
        base_filename = f"{date_prefix}_{title_clean}_è¨˜äº‹"
        file_path = create_unique_filename(self.share, base_filename)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        if self.write_file_safe(file_path, article_content):
            self.log_info(f"Article created: {file_path}")
            return file_path
        else:
            return None
    
    def _generate_article_content(self, permanent_data: Dict[str, any], literature_data: Dict[str, any]) -> str:
        """è¨˜äº‹ã®å†…å®¹ã‚’ç”Ÿæˆ"""
        metadata = literature_data['metadata']
        insights = literature_data['insights']
        main_points = literature_data['main_points']
        use_cases = literature_data['use_cases']
        
        # è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
        title = f"{metadata.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«')}ã‹ã‚‰å­¦ã¶å®Ÿè·µçš„ãªçŸ¥è¦‹"
        
        content = f"""# {title}

## ã¯ã˜ã‚ã«

æœ€è¿‘ã€{metadata.get('title', 'ã‚ã‚‹è¨˜äº‹')}ã‚’èª­ã‚“ã§ã€ã„ãã¤ã‹ã®é‡è¦ãªæ°—ã¥ãã‚’å¾—ã¾ã—ãŸã€‚
ã“ã®è¨˜äº‹ã§ã¯ã€ãã®å†…å®¹ã‚’æ•´ç†ã—ã€å®Ÿè·µçš„ãªè¦³ç‚¹ã‹ã‚‰è€ƒå¯Ÿã—ã¦ã¿ãŸã„ã¨æ€ã„ã¾ã™ã€‚

## è¨˜äº‹ã®æ¦‚è¦

å…ƒã®è¨˜äº‹ã§ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªç‚¹ãŒè­°è«–ã•ã‚Œã¦ã„ã¾ã—ãŸï¼š

"""
        
        # ä¸»è¦ãƒã‚¤ãƒ³ãƒˆã‚’è¨˜è¼‰
        for point in main_points[:3]:
            content += f"- {point}\n"
        
        content += """

## é‡è¦ãªæ´å¯Ÿ

### 1. å®Ÿè·µçš„ãªè¦–ç‚¹

"""
        
        if insights:
            content += f"{insights[0]}ã“ã¨ãŒã€ã“ã®è¨˜äº‹ã‹ã‚‰èª­ã¿å–ã‚Œã¾ã™ã€‚"
        
        content += """

### 2. å¿œç”¨ã®å¯èƒ½æ€§

ä»¥ä¸‹ã®ã‚ˆã†ãªå ´é¢ã§æ´»ç”¨ã§ãã‚‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ï¼š

"""
        
        for use_case in use_cases[:3]:
            content += f"- {use_case}\n"
        
        content += """

## ç­†è€…ã®æ„Ÿæƒ³

å€‹äººçš„ã«æœ€ã‚‚å°è±¡çš„ã ã£ãŸã®ã¯ã€"""
        
        if main_points:
            content += f"ã€Œ{main_points[0]}ã€ã¨ã„ã†ç‚¹ã§ã™ã€‚"
        
        content += """
ã“ã‚Œã¯æ—¥å¸¸ã®æ¥­å‹™ã‚„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãŠã„ã¦ã‚‚ã€é‡è¦ãªç¤ºå”†ã‚’ä¸ãˆã¦ãã‚Œã¾ã™ã€‚

## è¨˜äº‹ã®ãƒã‚¤ãƒ³ãƒˆ

1. **çŸ¥è­˜ã®ä½“ç³»åŒ–**: æ–­ç‰‡çš„ãªæƒ…å ±ã‚’æ§‹é€ åŒ–ã™ã‚‹ã“ã¨ã®é‡è¦æ€§
2. **å®Ÿè·µã¸ã®å¿œç”¨**: ç†è«–ã‚’å…·ä½“çš„ãªè¡Œå‹•ã«è½ã¨ã—è¾¼ã‚€æ–¹æ³•
3. **ç¶™ç¶šçš„ãªå­¦ç¿’**: æ–°ã—ã„çŸ¥è­˜ã‚’æ—¢å­˜ã®çŸ¥è­˜ã¨çµã³ã¤ã‘ã‚‹

## ã¾ã¨ã‚

"""
        
        content += f"""{metadata.get('title', 'ã“ã®è¨˜äº‹')}ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸçŸ¥è¦‹ã¯ã€å˜ãªã‚‹æƒ…å ±ä»¥ä¸Šã®ä¾¡å€¤ãŒã‚ã‚Šã¾ã™ã€‚
é‡è¦ãªã®ã¯ã€ã“ã‚Œã‚‰ã®çŸ¥è­˜ã‚’ã©ã®ã‚ˆã†ã«è‡ªåˆ†ã®æ–‡è„ˆã§æ´»ç”¨ã™ã‚‹ã‹ã¨ã„ã†ã“ã¨ã§ã™ã€‚

ä»Šå¾Œã‚‚ç¶™ç¶šçš„ã«å­¦ç¿’ã‚’ç¶šã‘ã€å®Ÿè·µçš„ãªçŸ¥è­˜ã¨ã—ã¦æ˜‡è¯ã•ã›ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ã€‚

---

**å…¬é–‹æ—¥**: {self.format_timestamp('%Y-%m-%d')}  
**ã‚«ãƒ†ã‚´ãƒª**: å­¦ç¿’ãƒãƒ¼ãƒˆ  
**ã‚¿ã‚°**: #share/blog {' '.join(metadata.get('tags', []))}  
**å‚è€ƒè³‡æ–™**: 
- [[{Path(literature_data['file_path']).stem}]]
- {metadata.get('source', '')}
"""
        
        return content
    
    def process_all_clips(self) -> List[Dict[str, any]]:
        """ã™ã¹ã¦ã®ã‚¯ãƒªãƒƒãƒ—ã‚’å‡¦ç†ã—ã¦è¨˜äº‹ã¾ã§ç”Ÿæˆ"""
        self.log_info("Starting full automation process")
        print("ğŸš€ Starting full automation: Clip â†’ Literature â†’ Permanent â†’ Article")
        
        # Step 1: Clipã‚’Literatureã«å‡¦ç†
        literature_files = self.process_clip_to_literature()
        
        if not literature_files:
            print("No clips to process or processing failed")
            return []
        
        generated_articles = []
        
        for lit_file in literature_files:
            try:
                print(f"\nğŸ“„ Processing: {lit_file.name}")
                
                # Step 2: æ´å¯Ÿã‚’æŠ½å‡º
                literature_data = self.extract_key_insights(lit_file)
                if not literature_data:
                    continue
                
                # Step 3: Permanentãƒãƒ¼ãƒˆä½œæˆ
                permanent_path, permanent_content = self.create_permanent_note(literature_data)
                if not permanent_path:
                    continue
                    
                print(f"  âœ“ Permanent note created: {permanent_path.name}")
                
                # Step 4: è¨˜äº‹ç”Ÿæˆ
                article_path = self.create_article(
                    {'path': permanent_path, 'content': permanent_content},
                    literature_data
                )
                if article_path:
                    print(f"  âœ“ Article created: {article_path.name}")
                    
                    generated_articles.append({
                        'literature': lit_file,
                        'permanent': permanent_path,
                        'article': article_path,
                        'metadata': literature_data['metadata']
                    })
                
            except Exception as e:
                self.log_error(f"Error processing {lit_file}", e)
                print(f"  âœ— Error: {str(e)}")
        
        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
        self._generate_automation_report(generated_articles)
        
        return generated_articles
    
    def _generate_automation_report(self, generated_articles: List[Dict[str, any]]) -> None:
        """è‡ªå‹•åŒ–å‡¦ç†ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report_path = self.generate_report_path("automation")
        
        content = f"""# Automation Report

**Date**: {self.format_timestamp()}
**Articles Generated**: {len(generated_articles)}

"""
        
        if generated_articles:
            content += "## Generated Articles\n\n"
            for item in generated_articles:
                content += f"""### {item['metadata'].get('title', 'Untitled')}
- Literature: `{item['literature'].name}`
- Permanent: `{item['permanent'].name}`
- Article: `{item['article'].name}`
- Source: {item['metadata'].get('source', 'Unknown')}

"""
        
        if self.write_file_safe(report_path, content):
            print(f"\nğŸ“Š Report generated: {report_path.name}")
            print(f"âœ… Total articles generated: {len(generated_articles)}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    vault_path = VAULT_PATH
    generator = AutoArticleGenerator(vault_path)
    
    # ã™ã¹ã¦ã®ã‚¯ãƒªãƒƒãƒ—ã‚’å‡¦ç†
    results = generator.process_all_clips()
    
    if results:
        print("\nğŸ‰ Automation complete!")
        print(f"Generated {len(results)} articles from clips")
    else:
        print("\nğŸ“­ No clips found to process")


if __name__ == "__main__":
    main()