#!/usr/bin/env python3
"""
Notionãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’å–å¾—ã—ã¦æ›´æ–°ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import os
import json
import requests
from datetime import datetime
import re
import time
from pathlib import Path

# è¨­å®š
NOTION_TOKEN = "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"
NOTION_VERSION = "2022-06-28"
HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": NOTION_VERSION,
    "Content-Type": "application/json"
}
OUTPUT_DIR = "/Users/hashiguchimasaki/project/obsidian/20_Literature/25_Notion"

# çµ±è¨ˆæƒ…å ±
stats = {
    "total_placeholder_files": 0,
    "successfully_updated": 0,
    "failed_updates": 0,
    "already_complete": 0,
    "start_time": None,
    "end_time": None,
    "errors": []
}

def is_placeholder_file(filepath):
    """ãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
        
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡Œæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    lines = content.strip().split('\n')
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã‚’é™¤ã„ãŸå®Ÿéš›ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„éƒ¨åˆ†ã‚’å–å¾—
    content_start = False
    content_lines = []
    for line in lines:
        if line.strip() == '---' and content_start:
            content_start = False
            continue
        elif line.strip() == '---' and not content_start:
            content_start = True
            continue
        elif not content_start and line.strip():
            content_lines.append(line)
    
    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå°‘ãªã„ï¼ˆ5è¡Œä»¥ä¸‹ï¼‰å ´åˆã¯ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã¨åˆ¤å®š
    return len(content_lines) <= 5

def extract_notion_id(filepath):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Notion IDã‚’æŠ½å‡º"""
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    match = re.search(r'notion_id:\s*([a-f0-9-]+)', content)
    if match:
        return match.group(1)
    return None

def get_page_content(page_id):
    """ãƒšãƒ¼ã‚¸å†…å®¹ã‚’å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰"""
    url = f"https://api.notion.com/v1/blocks/{page_id}/children"
    
    all_blocks = []
    has_more = True
    start_cursor = None
    
    while has_more:
        params = {"page_size": 100}
        if start_cursor:
            params["start_cursor"] = start_cursor
        
        response = requests.get(url, headers=HEADERS, params=params)
        if response.status_code == 200:
            data = response.json()
            blocks = data.get("results", [])
            all_blocks.extend(blocks)
            has_more = data.get("has_more", False)
            start_cursor = data.get("next_cursor")
        else:
            break
    
    return all_blocks

def block_to_markdown(block, indent_level=0):
    """ãƒ–ãƒ­ãƒƒã‚¯ã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã«å¤‰æ›"""
    block_type = block.get("type")
    indent = "  " * indent_level
    
    converters = {
        "paragraph": lambda b: f"{indent}{extract_text(b, 'paragraph')}",
        "heading_1": lambda b: f"{indent}# {extract_text(b, 'heading_1')}",
        "heading_2": lambda b: f"{indent}## {extract_text(b, 'heading_2')}",
        "heading_3": lambda b: f"{indent}### {extract_text(b, 'heading_3')}",
        "bulleted_list_item": lambda b: f"{indent}- {extract_text(b, 'bulleted_list_item')}",
        "numbered_list_item": lambda b: f"{indent}1. {extract_text(b, 'numbered_list_item')}",
        "to_do": lambda b: f"{indent}- [{'x' if b.get('to_do', {}).get('checked', False) else ' '}] {extract_text(b, 'to_do')}",
        "toggle": lambda b: f"{indent}<details>\n{indent}<summary>{extract_text(b, 'toggle')}</summary>\n{indent}</details>",
        "code": lambda b: format_code_block(b, indent),
        "quote": lambda b: f"{indent}> {extract_text(b, 'quote')}",
        "divider": lambda b: f"{indent}---",
        "table_of_contents": lambda b: f"{indent}[[TOC]]",
        "callout": lambda b: f"{indent}> ğŸ’¡ {extract_text(b, 'callout')}",
        "image": lambda b: format_image(b, indent),
        "video": lambda b: format_video(b, indent),
        "file": lambda b: format_file(b, indent),
        "bookmark": lambda b: format_bookmark(b, indent),
        "equation": lambda b: f"{indent}$${b.get('equation', {}).get('expression', '')}$$"
    }
    
    converter = converters.get(block_type)
    if converter:
        return converter(block)
    return ""

def extract_text(block, block_type):
    """ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    texts = block.get(block_type, {}).get("rich_text", [])
    return "".join([format_rich_text(t) for t in texts])

def format_rich_text(text_obj):
    """ãƒªãƒƒãƒãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    text = text_obj.get("plain_text", "")
    annotations = text_obj.get("annotations", {})
    
    if annotations.get("bold"):
        text = f"**{text}**"
    if annotations.get("italic"):
        text = f"*{text}*"
    if annotations.get("strikethrough"):
        text = f"~~{text}~~"
    if annotations.get("code"):
        text = f"`{text}`"
    
    if text_obj.get("href"):
        text = f"[{text}]({text_obj['href']})"
    
    return text

def format_code_block(block, indent):
    """ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    texts = block.get("code", {}).get("rich_text", [])
    code = "".join([t.get("plain_text", "") for t in texts])
    language = block.get("code", {}).get("language", "")
    return f"{indent}```{language}\n{code}\n{indent}```"

def format_image(block, indent):
    """ç”»åƒãƒ–ãƒ­ãƒƒã‚¯ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    image = block.get("image", {})
    if image.get("type") == "external":
        url = image.get("external", {}).get("url", "")
    else:
        url = image.get("file", {}).get("url", "")
    
    caption = "".join([t.get("plain_text", "") for t in image.get("caption", [])])
    if caption:
        return f"{indent}![{caption}]({url})"
    return f"{indent}![]({url})"

def format_video(block, indent):
    """ãƒ“ãƒ‡ã‚ªãƒ–ãƒ­ãƒƒã‚¯ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    video = block.get("video", {})
    if video.get("type") == "external":
        url = video.get("external", {}).get("url", "")
        return f"{indent}[Video: {url}]({url})"
    return ""

def format_file(block, indent):
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ–ãƒ­ãƒƒã‚¯ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    file = block.get("file", {})
    if file.get("type") == "external":
        url = file.get("external", {}).get("url", "")
    else:
        url = file.get("file", {}).get("url", "")
    
    name = file.get("name", "File")
    return f"{indent}[{name}]({url})"

def format_bookmark(block, indent):
    """ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ãƒ–ãƒ­ãƒƒã‚¯ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    bookmark = block.get("bookmark", {})
    url = bookmark.get("url", "")
    caption = "".join([t.get("plain_text", "") for t in bookmark.get("caption", [])])
    
    if caption:
        return f"{indent}[{caption}]({url})"
    return f"{indent}[Bookmark]({url})"

def update_file_with_content(filepath, notion_id):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã«å®Œå…¨ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿½åŠ """
    try:
        # æ—¢å­˜ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒ
        with open(filepath, 'r', encoding='utf-8') as f:
            existing_content = f.read()
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã‚’æŠ½å‡º
        metadata_match = re.search(r'^---\n(.*?)\n---\n', existing_content, re.DOTALL)
        if not metadata_match:
            print(f"  âœ— ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")
            return False
        
        metadata = metadata_match.group(0)
        
        # Notion APIã‹ã‚‰å®Œå…¨ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
        blocks = get_page_content(notion_id)
        
        if not blocks:
            print(f"  âœ— ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return False
        
        # ãƒ–ãƒ­ãƒƒã‚¯ã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã«å¤‰æ›
        content_lines = []
        for block in blocks:
            line = block_to_markdown(block)
            if line:
                content_lines.append(line)
                
            # ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ–ãƒ­ãƒƒã‚¯ã‚‚å‡¦ç†
            if block.get("has_children"):
                child_blocks = get_page_content(block["id"])
                for child_block in child_blocks:
                    child_line = block_to_markdown(child_block, indent_level=1)
                    if child_line:
                        content_lines.append(child_line)
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
        title = os.path.basename(filepath).replace('.md', '')
        
        # æ–°ã—ã„å†…å®¹ã‚’æ§‹ç¯‰
        new_content = metadata + f"\n# {title}\n\n" + "\n".join(content_lines)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        print(f"  âœ“ æ›´æ–°å®Œäº†: {len(blocks)} blocks")
        return True
        
    except Exception as e:
        print(f"  âœ— ã‚¨ãƒ©ãƒ¼: {str(e)}")
        stats["errors"].append(f"{filepath}: {str(e)}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    stats["start_time"] = time.time()
    
    print("=" * 60)
    print("Notion Placeholder Content Fetcher")
    print("=" * 60)
    
    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    print("\n1. ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ä¸­...")
    
    placeholder_files = []
    for filename in os.listdir(OUTPUT_DIR):
        if filename.endswith('.md'):
            filepath = os.path.join(OUTPUT_DIR, filename)
            if is_placeholder_file(filepath):
                notion_id = extract_notion_id(filepath)
                if notion_id:
                    placeholder_files.append((filepath, notion_id))
    
    stats["total_placeholder_files"] = len(placeholder_files)
    print(f"   è¦‹ã¤ã‹ã£ãŸãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼: {len(placeholder_files)} files")
    
    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    print("\n2. ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã—ã¦æ›´æ–°ä¸­...")
    print("-" * 60)
    
    for i, (filepath, notion_id) in enumerate(placeholder_files):
        filename = os.path.basename(filepath)
        print(f"\n[{i+1}/{len(placeholder_files)}] {filename}")
        print(f"  Notion ID: {notion_id}")
        
        if update_file_with_content(filepath, notion_id):
            stats["successfully_updated"] += 1
        else:
            stats["failed_updates"] += 1
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
        time.sleep(0.5)
    
    stats["end_time"] = time.time()
    
    # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
    print("\n" + "=" * 60)
    print("FETCH SUMMARY")
    print("=" * 60)
    print(f"ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['total_placeholder_files']}")
    print(f"æ›´æ–°æˆåŠŸ:                   {stats['successfully_updated']}")
    print(f"æ›´æ–°å¤±æ•—:                   {stats['failed_updates']}")
    print(f"å‡¦ç†æ™‚é–“:                   {stats['end_time'] - stats['start_time']:.2f} seconds")
    
    if stats["errors"]:
        print("\nã‚¨ãƒ©ãƒ¼è©³ç´°:")
        for error in stats["errors"][:10]:
            print(f"  - {error}")
        if len(stats["errors"]) > 10:
            print(f"  ... ä»– {len(stats['errors']) - 10} ä»¶ã®ã‚¨ãƒ©ãƒ¼")
    
    # çµ±è¨ˆæƒ…å ±ã‚’ä¿å­˜
    stats_file = os.path.join(OUTPUT_DIR, ".content_fetch_stats.json")
    with open(stats_file, 'w') as f:
        json.dump({
            "last_fetch": datetime.now().isoformat(),
            "placeholder_files": stats["total_placeholder_files"],
            "updated": stats["successfully_updated"],
            "failed": stats["failed_updates"],
            "duration_seconds": stats["end_time"] - stats["start_time"],
            "errors": stats["errors"]
        }, f, indent=2)
    
    print(f"\nçµ±è¨ˆæƒ…å ±ã‚’ä¿å­˜: {stats_file}")

if __name__ == "__main__":
    main()