#!/usr/bin/env python3
"""
Notionæ®µéšçš„åŒæœŸã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
"""
import os
import json
import requests
from datetime import datetime
import time

# è¨­å®š
NOTION_TOKEN = "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"
HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": "2022-06-28",
    "Content-Type": "application/json"
}
OUTPUT_DIR = "/Users/hashiguchimasaki/project/obsidian/20_Literature/25_Notion"
BATCH_SIZE = 50  # 1å›ã‚ãŸã‚Šã®ãƒšãƒ¼ã‚¸æ•°
MAX_RETRIES = 3

def save_progress(batch_num, total_synced, total_pages, errors):
    """é€²æ—ã‚’ä¿å­˜"""
    progress = {
        "last_batch": batch_num,
        "total_synced": total_synced,
        "total_pages": total_pages,
        "completion_rate": (total_synced / total_pages) * 100,
        "last_sync": datetime.now().isoformat(),
        "errors": errors[-10:]  # ç›´è¿‘10å€‹ã®ã‚¨ãƒ©ãƒ¼ã®ã¿
    }
    
    with open(os.path.join(OUTPUT_DIR, ".sync_progress.json"), 'w') as f:
        json.dump(progress, f, indent=2)

def load_progress():
    """é€²æ—ã‚’èª­ã¿è¾¼ã¿"""
    try:
        with open(os.path.join(OUTPUT_DIR, ".sync_progress.json"), 'r') as f:
            return json.load(f)
    except:
        return {"last_batch": 0, "total_synced": 0}

def get_all_page_ids():
    """å…¨ãƒšãƒ¼ã‚¸IDã‚’å–å¾—ï¼ˆè»½é‡ï¼‰"""
    url = "https://api.notion.com/v1/search"
    payload = {
        "filter": {"property": "object", "value": "page"},
        "page_size": 100
    }
    
    all_page_ids = []
    has_more = True
    start_cursor = None
    
    while has_more:
        if start_cursor:
            payload["start_cursor"] = start_cursor
        
        response = requests.post(url, headers=HEADERS, json=payload)
        if response.status_code == 200:
            data = response.json()
            for page in data.get("results", []):
                all_page_ids.append({
                    "id": page["id"],
                    "title": get_page_title(page),
                    "url": page.get("url", "")
                })
            has_more = data.get("has_more", False)
            start_cursor = data.get("next_cursor")
        else:
            print(f"Error: {response.status_code}")
            break
        
        # é€²æ—è¡¨ç¤º
        if len(all_page_ids) % 100 == 0:
            print(f"  Collected {len(all_page_ids)} page IDs...")
    
    return all_page_ids

def get_page_title(page):
    """ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—"""
    try:
        if 'properties' in page:
            for prop_name, prop_value in page['properties'].items():
                if prop_value['type'] == 'title' and prop_value.get('title'):
                    return prop_value['title'][0]['plain_text']
    except:
        pass
    return "Untitled"

def sync_batch(page_ids, batch_num, start_idx, end_idx):
    """ãƒãƒƒãƒåŒæœŸ"""
    print(f"\n=== Batch {batch_num}: Pages {start_idx+1}-{end_idx} ===")
    
    batch_pages = page_ids[start_idx:end_idx]
    synced = 0
    errors = []
    
    for i, page_info in enumerate(batch_pages):
        page_id = page_info["id"]
        title = page_info["title"]
        
        print(f"[{start_idx + i + 1}/{len(page_ids)}] {title[:50]}...")
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            filename = f"{title.replace('/', '_')[:100]}.md"
            filepath = os.path.join(OUTPUT_DIR, filename)
            
            if os.path.exists(filepath):
                print("  â­ï¸  Already exists, skipping")
                synced += 1
                continue
            
            # ç°¡æ˜“ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆé«˜é€ŸåŒ–ï¼‰
            metadata = f"""---
notion_id: {page_id}
title: {title}
url: {page_info.get('url', '')}
sync_status: placeholder
sync_time: {datetime.now().isoformat()}
---

# {title}

*This is a placeholder. Full content will be synced later.*

[Open in Notion]({page_info.get('url', '')})
"""
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(metadata)
            
            synced += 1
            print("  âœ… Placeholder created")
            
        except Exception as e:
            error_msg = f"{title}: {str(e)}"
            errors.append(error_msg)
            print(f"  âŒ Error: {str(e)}")
    
    return synced, errors

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    print("ğŸš€ Notion Batch Sync - Starting")
    print("=" * 60)
    
    # é€²æ—ã‚’ç¢ºèª
    progress = load_progress()
    start_batch = progress.get("last_batch", 0)
    
    if start_batch > 0:
        print(f"ğŸ“‹ Resuming from batch {start_batch + 1}")
    
    # å…¨ãƒšãƒ¼ã‚¸IDã‚’å–å¾—
    print("\n1. Collecting all page IDs...")
    all_page_ids = get_all_page_ids()
    total_pages = len(all_page_ids)
    
    print(f"   Total pages: {total_pages}")
    print(f"   Batch size: {BATCH_SIZE}")
    print(f"   Estimated batches: {(total_pages + BATCH_SIZE - 1) // BATCH_SIZE}")
    
    # ãƒãƒƒãƒå‡¦ç†
    print("\n2. Starting batch sync...")
    total_synced = progress.get("total_synced", 0)
    all_errors = []
    
    for batch_num in range(start_batch, (total_pages + BATCH_SIZE - 1) // BATCH_SIZE):
        start_idx = batch_num * BATCH_SIZE
        end_idx = min(start_idx + BATCH_SIZE, total_pages)
        
        batch_synced, batch_errors = sync_batch(all_page_ids, batch_num + 1, start_idx, end_idx)
        
        total_synced += batch_synced
        all_errors.extend(batch_errors)
        
        # é€²æ—ä¿å­˜
        save_progress(batch_num, total_synced, total_pages, all_errors)
        
        completion_rate = (total_synced / total_pages) * 100
        print(f"\nğŸ“Š Progress: {total_synced}/{total_pages} ({completion_rate:.1f}%)")
        
        # ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
        if batch_errors:
            print(f"âŒ Batch errors: {len(batch_errors)}")
        
        # APIåˆ¶é™ã‚’è€ƒæ…®ã—ãŸå¾…æ©Ÿæ™‚é–“
        if batch_num < ((total_pages + BATCH_SIZE - 1) // BATCH_SIZE) - 1:
            print("â³ Waiting 2 seconds to respect API limits...")
            time.sleep(2)
    
    # æœ€çµ‚çµæœ
    print("\n" + "=" * 60)
    print("ğŸ‰ BATCH SYNC COMPLETED")
    print("=" * 60)
    print(f"ğŸ“ˆ Total synced: {total_synced}/{total_pages}")
    print(f"ğŸ¯ Completion rate: {(total_synced/total_pages)*100:.1f}%")
    print(f"âŒ Total errors: {len(all_errors)}")
    print(f"ğŸ“ Output directory: {OUTPUT_DIR}")
    
    if all_errors:
        print(f"\nâš ï¸  Last few errors:")
        for error in all_errors[-5:]:
            print(f"   â€¢ {error}")

if __name__ == "__main__":
    main()