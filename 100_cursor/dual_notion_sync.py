#!/usr/bin/env python3
"""
2ã¤ã®Notionã‚¢ã‚«ã‚¦ãƒ³ãƒˆçµ±åˆåŒæœŸã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import os
import json
import requests
from datetime import datetime
import time
import re

# è¨­å®š
NOTION_ACCOUNTS = {
    "Main": {
        "token": "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",
        "output_dir": "/Users/hashiguchimasaki/project/obsidian/20_Literature/25_Notion/Main"
    },
    "Secondary": {
        "token": "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",
        "output_dir": "/Users/hashiguchimasaki/project/obsidian/20_Literature/25_Notion/Secondary"
    }
}

NOTION_VERSION = "2022-06-28"
BATCH_SIZE = 30  # APIåˆ¶é™ã‚’è€ƒæ…®ã—ã¦ã•ã‚‰ã«å°ã•ã

def get_headers(token):
    return {
        "Authorization": f"Bearer {token}",
        "Notion-Version": NOTION_VERSION,
        "Content-Type": "application/json"
    }

def sanitize_filename(filename):
    """ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚º"""
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    return filename.strip()[:100] or "Untitled"

def get_page_title(page):
    """ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—"""
    try:
        if 'properties' in page:
            for prop_name, prop_value in page['properties'].items():
                if prop_value['type'] == 'title' and prop_value.get('title'):
                    return prop_value['title'][0]['plain_text']
    except:
        pass
    return "Untitled"

def create_placeholder_batch(account_name, token, output_dir, batch_size=50):
    """ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒãƒƒãƒä½œæˆ"""
    print(f"\nğŸš€ Creating placeholders for {account_name} account")
    print("-" * 50)
    
    os.makedirs(output_dir, exist_ok=True)
    headers = get_headers(token)
    
    # å…¨ãƒšãƒ¼ã‚¸IDã‚’é«˜é€Ÿå–å¾—
    url = "https://api.notion.com/v1/search"
    payload = {
        "filter": {"property": "object", "value": "page"},
        "page_size": 100
    }
    
    all_pages = []
    has_more = True
    start_cursor = None
    
    while has_more:
        if start_cursor:
            payload["start_cursor"] = start_cursor
        
        response = requests.post(url, headers=headers, json=payload)
        if response.status_code == 200:
            data = response.json()
            batch_pages = data.get("results", [])
            all_pages.extend(batch_pages)
            has_more = data.get("has_more", False)
            start_cursor = data.get("next_cursor")
            
            if len(all_pages) % 100 == 0:
                print(f"  ğŸ“¥ Fetched {len(all_pages)} pages...")
        else:
            print(f"  âŒ Error: {response.status_code}")
            break
    
    print(f"  ğŸ“Š Total pages to process: {len(all_pages)}")
    
    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ä½œæˆ
    created = 0
    skipped = 0
    
    for i, page in enumerate(all_pages):
        page_id = page['id']
        title = get_page_title(page)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åä½œæˆ
        filename = f"{sanitize_filename(title)}.md"
        filepath = os.path.join(output_dir, filename)
        
        # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
        if os.path.exists(filepath):
            skipped += 1
            continue
        
        # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ä½œæˆ
        metadata = f"""---
notion_id: {page_id}
account: {account_name}
title: {title}
url: {page.get('url', '')}
created_time: {page.get('created_time', '')}
last_edited_time: {page.get('last_edited_time', '')}
sync_status: placeholder
sync_time: {datetime.now().isoformat()}
---

# {title}

*ğŸ”„ This is a placeholder file from Notion {account_name} account.*

**Original URL**: {page.get('url', '')}

**Status**: Content will be synced in a future update.

**Page ID**: `{page_id}`

---

*Generated by Obsidian-Notion sync at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(metadata)
            created += 1
            
            if (i + 1) % 50 == 0:
                print(f"  âœ… Progress: {i + 1}/{len(all_pages)} ({((i+1)/len(all_pages)*100):.1f}%)")
                
        except Exception as e:
            print(f"  âŒ Error creating {filename}: {str(e)}")
    
    # çµ±è¨ˆæƒ…å ±ä¿å­˜
    stats = {
        "account": account_name,
        "total_pages": len(all_pages),
        "placeholders_created": created,
        "skipped_existing": skipped,
        "sync_time": datetime.now().isoformat(),
        "status": "placeholders_created"
    }
    
    with open(os.path.join(output_dir, ".sync_stats.json"), 'w') as f:
        json.dump(stats, f, indent=2)
    
    return stats

def get_recent_pages(token, account_name, limit=50):
    """2025å¹´ã«å…¥ã£ã¦ã‹ã‚‰ç·¨é›†ã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã‚’å–å¾—"""
    print(f"ğŸ“… Getting 2025 pages for {account_name}...")
    
    headers = get_headers(token)
    url = "https://api.notion.com/v1/search"
    
    # 2025å¹´1æœˆ1æ—¥ä»¥é™ã®ãƒšãƒ¼ã‚¸ã‚’å–å¾—
    from datetime import datetime as dt
    year_2025_start = "2025-01-01T00:00:00.000Z"
    
    all_recent_pages = []
    has_more = True
    start_cursor = None
    
    try:
        while has_more and len(all_recent_pages) < 200:  # æœ€å¤§200ãƒšãƒ¼ã‚¸ã¾ã§
            payload = {
                "filter": {"property": "object", "value": "page"},
                "sort": {"direction": "descending", "timestamp": "last_edited_time"},
                "page_size": 100
            }
            
            if start_cursor:
                payload["start_cursor"] = start_cursor
            
            response = requests.post(url, headers=headers, json=payload)
            if response.status_code == 200:
                data = response.json()
                batch_pages = data.get("results", [])
                
                for page in batch_pages:
                    last_edited = page.get("last_edited_time", "")
                    
                    # 2025å¹´ä»¥é™ã«ç·¨é›†ã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯
                    if last_edited >= year_2025_start:
                        page_info = {
                            "id": page["id"],
                            "title": get_page_title(page),
                            "url": page.get("url", ""),
                            "last_edited_time": last_edited,
                            "created_time": page.get("created_time", "")
                        }
                        all_recent_pages.append(page_info)
                    else:
                        # 2025å¹´ã‚ˆã‚Šå¤ã„ãƒšãƒ¼ã‚¸ã«åˆ°é”ã—ãŸã‚‰çµ‚äº†
                        has_more = False
                        break
                
                has_more = data.get("has_more", False) and has_more
                start_cursor = data.get("next_cursor")
                
                if len(all_recent_pages) % 20 == 0:
                    print(f"   ğŸ“¥ Found {len(all_recent_pages)} pages from 2025...")
            else:
                print(f"   âŒ Error: {response.status_code}")
                break
        
        # æŒ‡å®šã—ãŸåˆ¶é™æ•°ã¾ã§çµã‚‹
        filtered_pages = all_recent_pages[:limit]
        
        print(f"   âœ… Found {len(filtered_pages)} pages from 2025 (total checked: {len(all_recent_pages)})")
        return filtered_pages
        
    except Exception as e:
        print(f"   âŒ Error: {str(e)}")
        return []

def sync_page_content(token, account_name, page_info, output_dir):
    """å€‹åˆ¥ãƒšãƒ¼ã‚¸ã®å®Œå…¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åŒæœŸ"""
    page_id = page_info["id"]
    title = page_info["title"]
    
    print(f"   ğŸ”„ Syncing: {title[:50]}...")
    
    headers = get_headers(token)
    
    try:
        # ãƒšãƒ¼ã‚¸è©³ç´°æƒ…å ±ã‚’å–å¾—
        page_url = f"https://api.notion.com/v1/pages/{page_id}"
        page_response = requests.get(page_url, headers=headers)
        
        if page_response.status_code != 200:
            return False, f"Failed to get page details: {page_response.status_code}"
        
        page_data = page_response.json()
        
        # ãƒšãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆãƒ–ãƒ­ãƒƒã‚¯ï¼‰ã‚’å–å¾—
        blocks_url = f"https://api.notion.com/v1/blocks/{page_id}/children"
        blocks_response = requests.get(blocks_url, headers=headers)
        
        if blocks_response.status_code != 200:
            return False, f"Failed to get page blocks: {blocks_response.status_code}"
        
        blocks_data = blocks_response.json()
        
        # Markdownãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        filename = f"{sanitize_filename(title)}.md"
        filepath = os.path.join(output_dir, filename)
        
        # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ä½œæˆ
        frontmatter = f"""---
notion_id: {page_id}
account: {account_name}
title: {title}
url: {page_info.get('url', '')}
created_time: {page_info.get('created_time', '')}
last_edited_time: {page_info.get('last_edited_time', '')}
sync_status: full_content
sync_time: {datetime.now().isoformat()}
---

# {title}

"""
        
        # ãƒ–ãƒ­ãƒƒã‚¯ã‚’Markdownã«å¤‰æ›
        content = ""
        for block in blocks_data.get("results", []):
            block_content = convert_block_to_markdown(block)
            if block_content:
                content += block_content + "\n\n"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        full_content = frontmatter + content + f"\n---\n\n*Synced from Notion {account_name} account at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(full_content)
        
        return True, "Success"
        
    except Exception as e:
        return False, str(e)

def convert_block_to_markdown(block):
    """Notionãƒ–ãƒ­ãƒƒã‚¯ã‚’Markdownã«å¤‰æ›"""
    block_type = block.get("type", "")
    
    if block_type == "paragraph":
        return convert_rich_text(block.get("paragraph", {}).get("rich_text", []))
    elif block_type == "heading_1":
        return "# " + convert_rich_text(block.get("heading_1", {}).get("rich_text", []))
    elif block_type == "heading_2":
        return "## " + convert_rich_text(block.get("heading_2", {}).get("rich_text", []))
    elif block_type == "heading_3":
        return "### " + convert_rich_text(block.get("heading_3", {}).get("rich_text", []))
    elif block_type == "bulleted_list_item":
        return "- " + convert_rich_text(block.get("bulleted_list_item", {}).get("rich_text", []))
    elif block_type == "numbered_list_item":
        return "1. " + convert_rich_text(block.get("numbered_list_item", {}).get("rich_text", []))
    elif block_type == "code":
        code_block = block.get("code", {})
        language = code_block.get("language", "")
        text = convert_rich_text(code_block.get("rich_text", []))
        return f"```{language}\n{text}\n```"
    else:
        # ãã®ä»–ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ—ã¯ç°¡å˜ãªãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›
        return f"*[{block_type}]*"

def convert_rich_text(rich_text_array):
    """ãƒªãƒƒãƒãƒ†ã‚­ã‚¹ãƒˆé…åˆ—ã‚’ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
    result = ""
    for text_obj in rich_text_array:
        text = text_obj.get("plain_text", "")
        annotations = text_obj.get("annotations", {})
        
        if annotations.get("bold", False):
            text = f"**{text}**"
        if annotations.get("italic", False):
            text = f"*{text}*"
        if annotations.get("code", False):
            text = f"`{text}`"
        
        result += text
    
    return result

def sync_recent_pages_content(limit=30):
    """2025å¹´ã«ç·¨é›†ã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã®å®Œå…¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åŒæœŸ"""
    print("ğŸ”„ 2025 Pages Content Sync")
    print("=" * 60)
    
    all_synced = 0
    all_errors = []
    
    for account_name, config in NOTION_ACCOUNTS.items():
        print(f"\nğŸ“Š Syncing 2025 pages for {account_name}")
        print("-" * 40)
        
        # 2025å¹´ã«ç·¨é›†ã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã‚’å–å¾—
        recent_pages = get_recent_pages(config["token"], account_name, limit)
        
        if not recent_pages:
            print(f"   âš ï¸  No recent pages found for {account_name}")
            continue
        
        # å„ãƒšãƒ¼ã‚¸ã‚’åŒæœŸ
        synced_count = 0
        errors = []
        
        for page_info in recent_pages:
            success, message = sync_page_content(
                config["token"], 
                account_name, 
                page_info, 
                config["output_dir"]
            )
            
            if success:
                synced_count += 1
                print(f"     âœ… {page_info['title'][:30]}...")
            else:
                errors.append(f"{page_info['title']}: {message}")
                print(f"     âŒ {page_info['title'][:30]}... - {message}")
            
            # APIåˆ¶é™å¯¾ç­–
            time.sleep(0.5)
        
        all_synced += synced_count
        all_errors.extend(errors)
        
        print(f"\n   ğŸ“Š {account_name} Summary:")
        print(f"   âœ… Synced: {synced_count}/{len(recent_pages)}")
        if errors:
            print(f"   âŒ Errors: {len(errors)}")
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("ğŸ‰ 2025 CONTENT SYNC SUMMARY")
    print("=" * 60)
    print(f"âœ… Total pages synced: {all_synced}")
    print(f"âŒ Total errors: {len(all_errors)}")
    
    if all_errors:
        print(f"\nâš ï¸  Errors encountered:")
        for error in all_errors[-5:]:  # æœ€æ–°5å€‹ã®ã‚¨ãƒ©ãƒ¼ã®ã¿è¡¨ç¤º
            print(f"   â€¢ {error}")
    
    return all_synced, all_errors

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "content":
        # Phase 2: 2025å¹´ã«ç·¨é›†ã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åŒæœŸ
        limit = int(sys.argv[2]) if len(sys.argv) > 2 else 30
        sync_recent_pages_content(limit)
        return
    
    # Phase 1: ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ä½œæˆï¼ˆæ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ï¼‰
    print("ğŸ”„ Dual Notion Account Sync - Placeholder Creation")
    print("=" * 60)
    
    all_stats = {}
    total_pages = 0
    total_created = 0
    
    for account_name, config in NOTION_ACCOUNTS.items():
        start_time = time.time()
        
        stats = create_placeholder_batch(
            account_name, 
            config["token"], 
            config["output_dir"]
        )
        
        end_time = time.time()
        elapsed = end_time - start_time
        
        all_stats[account_name] = stats
        total_pages += stats["total_pages"]
        total_created += stats["placeholders_created"]
        
        print(f"\nğŸ“Š {account_name} Account Summary:")
        print(f"   ğŸ“„ Total pages: {stats['total_pages']}")
        print(f"   âœ… Created: {stats['placeholders_created']}")
        print(f"   â­ï¸  Skipped: {stats['skipped_existing']}")
        print(f"   â±ï¸  Time: {elapsed:.1f} seconds")
        print(f"   ğŸ“‚ Output: {config['output_dir']}")
    
    # å…¨ä½“ã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("ğŸ‰ DUAL SYNC SUMMARY")
    print("=" * 60)
    print(f"ğŸ“Š Total pages across accounts: {total_pages}")
    print(f"âœ… Total placeholders created: {total_created}")
    print(f"ğŸ“ Output structure:")
    for account_name, config in NOTION_ACCOUNTS.items():
        print(f"   ğŸ“‚ {account_name}: {config['output_dir']}")
    
    # å…¨ä½“çµ±è¨ˆä¿å­˜
    overall_stats = {
        "total_pages": total_pages,
        "total_created": total_created,
        "accounts": all_stats,
        "sync_time": datetime.now().isoformat()
    }
    
    base_dir = "/Users/hashiguchimasaki/project/obsidian/20_Literature/25_Notion"
    with open(os.path.join(base_dir, "dual_sync_summary.json"), 'w') as f:
        json.dump(overall_stats, f, indent=2)
    
    print(f"\nğŸ’¾ Summary saved to: {base_dir}/dual_sync_summary.json")
    
    # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ææ¡ˆ
    print(f"\nğŸ¯ NEXT STEPS:")
    print("1. Review created placeholder files in Obsidian")
    print("2. Run: python3 dual_notion_sync.py content [limit]")
    print("3. Set up automated incremental sync")

if __name__ == "__main__":
    main()