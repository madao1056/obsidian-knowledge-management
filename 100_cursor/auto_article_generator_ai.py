#!/usr/bin/env python3
"""
AIçµ±åˆç‰ˆè‡ªå‹•è¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
Claude APIã‚’ä½¿ç”¨ã—ãŸé«˜å“è³ªãªè¨˜äº‹ç”Ÿæˆ
"""

import os
import re
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
import subprocess

# Claude APIè¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ã“ã“ã«ç›´æ¥è¨­å®šï¼‰
# export CLAUDE_API_KEY="your-api-key"

class AIArticleGenerator:
    def __init__(self, vault_path, api_key=None):
        self.vault_path = Path(vault_path)
        self.inbox_clip = self.vault_path / "00_Inbox" / "clip"
        self.literature = self.vault_path / "20_Literature"
        self.permanent = self.vault_path / "30_Permanent"
        self.share = self.vault_path / "70_Share" / "78_Personal"
        self.log_dir = self.vault_path / "100_cursor" / "logs"
        
        # APIè¨­å®š
        self.api_key = api_key or os.environ.get('CLAUDE_API_KEY')
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        self.log_dir.mkdir(exist_ok=True)
        self.share.mkdir(exist_ok=True)
        
        # ãƒ­ã‚¬ãƒ¼ã‚’è¨­å®š
        self.setup_logger()
    
    def setup_logger(self):
        """ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­å®š"""
        log_file = self.log_dir / f"ai_article_{datetime.now().strftime('%Y%m%d')}.log"
        
        self.logger = logging.getLogger('AIArticleGenerator')
        self.logger.setLevel(logging.INFO)
        
        fh = logging.FileHandler(log_file, encoding='utf-8')
        fh.setLevel(logging.INFO)
        
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        fh.setFormatter(formatter)
        
        self.logger.addHandler(fh)
    
    def check_claude_api(self):
        """Claude APIãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        if not self.api_key:
            self.logger.warning("Claude API key not found. Using basic mode.")
            return False
        
        try:
            import anthropic
            self.client = anthropic.Anthropic(api_key=self.api_key)
            return True
        except ImportError:
            self.logger.warning("anthropic package not installed. Run: pip install anthropic")
            return False
        except Exception as e:
            self.logger.error(f"Error initializing Claude API: {e}")
            return False
    
    def generate_with_claude(self, prompt: str, system_prompt: str = "") -> Optional[str]:
        """Claude APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
        if not hasattr(self, 'client'):
            return None
        
        try:
            message = self.client.messages.create(
                model="claude-3-opus-20240229",
                max_tokens=4000,
                temperature=0.7,
                system=system_prompt,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            return message.content[0].text
        except Exception as e:
            self.logger.error(f"Claude API error: {e}")
            return None
    
    def extract_and_enhance_content(self, file_path):
        """AIã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†æãƒ»å¼·åŒ–"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åŸºæœ¬çš„ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        metadata = self._extract_basic_metadata(content)
        
        # AIãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯å¼·åŒ–
        if hasattr(self, 'client'):
            enhanced_data = self._enhance_with_ai(content, metadata)
            return enhanced_data
        else:
            # AIãªã—ã®å ´åˆã¯åŸºæœ¬ç‰ˆã‚’ä½¿ç”¨
            from auto_article_generator import AutoArticleGenerator
            basic_generator = AutoArticleGenerator(self.vault_path)
            return basic_generator.extract_key_insights(file_path)
    
    def _extract_basic_metadata(self, content):
        """åŸºæœ¬çš„ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º"""
        metadata = {}
        
        title_match = re.search(r'^# (.+)$', content, re.MULTILINE)
        if title_match:
            metadata['title'] = title_match.group(1)
        
        source_match = re.search(r'- \*\*ã‚½ãƒ¼ã‚¹\*\*: (.+)$', content, re.MULTILINE)
        if source_match:
            metadata['source'] = source_match.group(1)
        
        return metadata
    
    def _enhance_with_ai(self, content, metadata):
        """AIã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†æãƒ»å¼·åŒ–"""
        self.logger.info("Enhancing content with AI")
        
        system_prompt = """ã‚ãªãŸã¯çŸ¥è­˜ç®¡ç†ã®å°‚é–€å®¶ã§ã™ã€‚
æä¾›ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†æã—ã€ä»¥ä¸‹ã®å½¢å¼ã§JSONã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
{
    "title": "è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«",
    "summary": "200æ–‡å­—ç¨‹åº¦ã®è¦ç´„",
    "key_insights": ["æ´å¯Ÿ1", "æ´å¯Ÿ2", "æ´å¯Ÿ3"],
    "practical_applications": ["å¿œç”¨1", "å¿œç”¨2", "å¿œç”¨3"],
    "questions": ["ç–‘å•1", "ç–‘å•2"],
    "connections": ["é–¢é€£ãƒˆãƒ”ãƒƒã‚¯1", "é–¢é€£ãƒˆãƒ”ãƒƒã‚¯2"],
    "category": "Tech/Philosophy/Productivity/AI/Product"
}"""
        
        prompt = f"""ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†æã—ã¦ãã ã•ã„ï¼š

{content}

ä¸Šè¨˜ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰é‡è¦ãªæ´å¯Ÿã‚’æŠ½å‡ºã—ã€æŒ‡å®šã•ã‚ŒãŸJSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚"""
        
        response = self.generate_with_claude(prompt, system_prompt)
        
        if response:
            try:
                analysis = json.loads(response)
                return {
                    'metadata': {**metadata, **analysis},
                    'insights': analysis.get('key_insights', []),
                    'applications': analysis.get('practical_applications', []),
                    'category': analysis.get('category', 'Tech')
                }
            except json.JSONDecodeError:
                self.logger.error("Failed to parse AI response as JSON")
        
        return None
    
    def generate_high_quality_article(self, data):
        """AIã‚’ä½¿ç”¨ã—ã¦é«˜å“è³ªãªè¨˜äº‹ã‚’ç”Ÿæˆ"""
        if not hasattr(self, 'client'):
            # AIãªã—ã®å ´åˆã¯åŸºæœ¬ç‰ˆã‚’ä½¿ç”¨
            from auto_article_generator import AutoArticleGenerator
            basic_generator = AutoArticleGenerator(self.vault_path)
            return basic_generator._generate_article_content({}, data)
        
        system_prompt = """ã‚ãªãŸã¯å„ªã‚ŒãŸãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®è¦ä»¶ã§è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š
- 5000-7000æ–‡å­—ç¨‹åº¦
- èª­è€…ã‚’å¼•ãè¾¼ã‚€ãƒ•ãƒƒã‚¯æ–‡ã‹ã‚‰é–‹å§‹
- å…·ä½“ä¾‹ã‚’è±Šå¯Œã«å«ã‚ã‚‹
- å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›
- å€‹äººçš„ãªæ„Ÿæƒ³ã‚„è€ƒå¯Ÿã‚’å«ã‚ã‚‹
- æ—¥æœ¬èªã§åŸ·ç­†"""
        
        prompt = f"""ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«ã€é­…åŠ›çš„ãªè¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

ã‚¿ã‚¤ãƒˆãƒ«: {data['metadata'].get('title', 'Untitled')}
è¦ç´„: {data['metadata'].get('summary', '')}
ä¸»è¦ãªæ´å¯Ÿ: {', '.join(data.get('insights', []))}
å®Ÿè·µçš„å¿œç”¨: {', '.join(data.get('applications', []))}

è¨˜äº‹ã¯ä»¥ä¸‹ã®æ§‹æˆã«ã—ã¦ãã ã•ã„ï¼š
1. ãƒ•ãƒƒã‚¯æ–‡ï¼ˆèª­è€…ã®èˆˆå‘³ã‚’å¼•ãå°å…¥ï¼‰
2. è¨˜äº‹ã®æ¦‚è¦
3. ä¸»è¦ãƒã‚¤ãƒ³ãƒˆï¼ˆ3-5å€‹ï¼‰
4. å®Ÿè·µçš„ãªæ´»ç”¨ä¾‹
5. ç­†è€…ã®æ„Ÿæƒ³
6. è¨˜äº‹ã®ãƒã‚¤ãƒ³ãƒˆï¼ˆã¾ã¨ã‚ï¼‰
7. ä»Šå¾Œã®å±•æœ›

ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""
        
        article = self.generate_with_claude(prompt, system_prompt)
        
        if article:
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            footer = f"""

---

**ç”Ÿæˆæ—¥**: {datetime.now().strftime('%Y-%m-%d')}  
**ã‚«ãƒ†ã‚´ãƒª**: {data.get('category', 'Tech')}  
**ã‚¿ã‚°**: #share/blog #ai-generated #{data.get('category', 'tech').lower()}  
**ã‚½ãƒ¼ã‚¹**: {data['metadata'].get('source', 'Unknown')}

ğŸ¤– ã“ã®è¨˜äº‹ã¯AIã‚’æ´»ç”¨ã—ã¦ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚
"""
            return article + footer
        
        return None
    
    def process_with_ai(self):
        """AIçµ±åˆç‰ˆã®å®Œå…¨è‡ªå‹•å‡¦ç†"""
        print("ğŸ¤– AI-Powered Article Generation")
        
        # Claude APIãƒã‚§ãƒƒã‚¯
        ai_available = self.check_claude_api()
        if ai_available:
            print("âœ“ Claude API connected")
        else:
            print("âš ï¸  Running in basic mode (no AI)")
        
        # Step 1: Clipã‚’Literatureã«å‡¦ç†
        print("\nğŸ“‹ Step 1: Processing clips...")
        result = subprocess.run(
            ['python3', str(self.vault_path / '100_cursor' / 'process_clip.py')],
            capture_output=True,
            text=True
        )
        
        if result.returncode != 0:
            print("âœ— Failed to process clips")
            return []
        
        # æœ€è¿‘ã®Literatureãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        recent_files = []
        cutoff_time = datetime.now().timestamp() - (5 * 60)  # 5åˆ†ä»¥å†…
        
        for file_path in self.literature.glob("**/*.md"):
            if file_path.stat().st_mtime > cutoff_time:
                recent_files.append(file_path)
        
        if not recent_files:
            print("No new files to process")
            return []
        
        generated_articles = []
        
        for lit_file in recent_files:
            try:
                print(f"\nğŸ“„ Processing: {lit_file.name}")
                
                # Step 2: AIã§åˆ†æ
                print("  ğŸ” Analyzing content...")
                analysis = self.extract_and_enhance_content(lit_file)
                
                if not analysis:
                    print("  âœ— Analysis failed")
                    continue
                
                # Step 3: Permanentãƒãƒ¼ãƒˆä½œæˆ
                print("  ğŸ’¡ Creating permanent note...")
                permanent_path = self._create_enhanced_permanent(analysis)
                
                # Step 4: è¨˜äº‹ç”Ÿæˆ
                print("  âœï¸  Generating article...")
                article_content = self.generate_high_quality_article(analysis)
                
                if article_content:
                    # è¨˜äº‹ã‚’ä¿å­˜
                    date_prefix = datetime.now().strftime('%Y%m%d')
                    title = analysis['metadata'].get('title', 'Untitled')
                    title_clean = re.sub(r'[^\w\s-]', '', title)[:30].replace(' ', '_')
                    filename = f"{date_prefix}_{title_clean}_AIè¨˜äº‹.md"
                    article_path = self.share / filename
                    
                    with open(article_path, 'w', encoding='utf-8') as f:
                        f.write(article_content)
                    
                    print(f"  âœ“ Article saved: {article_path.name}")
                    
                    generated_articles.append({
                        'literature': lit_file,
                        'permanent': permanent_path,
                        'article': article_path,
                        'metadata': analysis['metadata']
                    })
                
            except Exception as e:
                self.logger.error(f"Error processing {lit_file}: {str(e)}")
                print(f"  âœ— Error: {str(e)}")
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self._generate_report(generated_articles)
        
        return generated_articles
    
    def _create_enhanced_permanent(self, analysis):
        """å¼·åŒ–ã•ã‚ŒãŸPermanentãƒãƒ¼ãƒˆä½œæˆ"""
        category_map = {
            'Tech': '32_Tech',
            'Philosophy': '31_Philosophy',
            'Productivity': '33_Productivity',
            'AI': '35_AI',
            'Product': '34_Product'
        }
        
        category = category_map.get(analysis.get('category', 'Tech'), '32_Tech')
        
        content = f"""# {analysis['metadata'].get('title', 'Untitled')} - æ·±ã„æ´å¯Ÿ

## æ¦‚è¦
{analysis['metadata'].get('summary', '')}

## é‡è¦ãªæ´å¯Ÿ
"""
        
        for i, insight in enumerate(analysis.get('insights', []), 1):
            content += f"\n### {i}. {insight}\n"
        
        content += "\n## å®Ÿè·µã¸ã®å¿œç”¨\n"
        
        for app in analysis.get('applications', []):
            content += f"- {app}\n"
        
        content += f"""

## é–¢é€£ãƒˆãƒ”ãƒƒã‚¯
{', '.join(['[[' + conn + ']]' for conn in analysis['metadata'].get('connections', [])])}

---

**ä½œæˆæ—¥**: {datetime.now().strftime('%Y-%m-%d')}  
**ã‚«ãƒ†ã‚´ãƒª**: {analysis.get('category', 'Tech')}  
**ã‚¿ã‚°**: #permanent #{analysis.get('category', 'tech').lower()} #ai-enhanced
"""
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        title_clean = re.sub(r'[^\w\s-]', '', analysis['metadata'].get('title', 'Untitled'))[:30]
        filename = f"{title_clean}_æ·±ã„æ´å¯Ÿ.md"
        file_path = self.permanent / category / filename
        file_path.parent.mkdir(exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return file_path
    
    def _generate_report(self, articles):
        """å‡¦ç†ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report_path = self.vault_path / "100_cursor" / "reports" / f"ai_generation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"# AI Article Generation Report\n\n")
            f.write(f"**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**AI Mode**: {'Enabled' if hasattr(self, 'client') else 'Disabled'}\n")
            f.write(f"**Articles Generated**: {len(articles)}\n\n")
            
            for item in articles:
                f.write(f"## {item['metadata'].get('title', 'Untitled')}\n")
                f.write(f"- Category: {item['metadata'].get('category', 'Unknown')}\n")
                f.write(f"- Summary: {item['metadata'].get('summary', 'N/A')[:100]}...\n\n")
        
        print(f"\nğŸ“Š Report: {report_path.name}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    vault_path = "/Users/hashiguchimasaki/project/obsidian"
    
    # API keyã®è¨­å®šæ–¹æ³•ã‚’è¡¨ç¤º
    if not os.environ.get('CLAUDE_API_KEY'):
        print("ğŸ’¡ Tip: Set CLAUDE_API_KEY environment variable for AI features")
        print("   export CLAUDE_API_KEY='your-api-key'")
        print("   Or install: pip install anthropic")
        print("")
    
    generator = AIArticleGenerator(vault_path)
    results = generator.process_with_ai()
    
    if results:
        print(f"\nğŸ‰ Generated {len(results)} AI-powered articles!")
    else:
        print("\nğŸ“­ No clips to process")


if __name__ == "__main__":
    main()