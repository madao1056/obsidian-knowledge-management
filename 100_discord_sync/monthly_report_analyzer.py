#!/usr/bin/env python3
"""
æœˆå ±åˆ†æã‚·ã‚¹ãƒ†ãƒ 
æ—¥å ±ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã€PDCAã‚µã‚¤ã‚¯ãƒ«ã®åˆ†æã‚’è¡Œã†
"""

import json
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from collections import defaultdict
import logging

# Notionã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from notion_integration import NotionIntegration
except ImportError:
    NotionIntegration = None

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MonthlyReportAnalyzer:
    def __init__(self):
        self.inbox_path = Path(__file__).parent.parent / "00_Inbox" / "discord"
        self.support_path = Path(__file__).parent.parent / "03_Support" / "ã‚°ãƒƒã‚µãƒãƒ»ãƒ©ãƒœ"
        self.members_path = self.support_path / "ãƒ¡ãƒ³ãƒãƒ¼ç®¡ç†"
        self.members_path.mkdir(parents=True, exist_ok=True)
        
        # Notionã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        self.notion = NotionIntegration() if NotionIntegration else None
        
    def analyze_member_monthly_data(self, member_name: str, year: int, month: int) -> Dict:
        """ç‰¹å®šãƒ¡ãƒ³ãƒãƒ¼ã®æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ"""
        
        # è©²å½“æœˆã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
        monthly_data = {
            "daily_reports": [],
            "questions": [],
            "progress": [],
            "working_hours": [],
            "revenues": [],
            "sales_activities": [],
            "completed_tasks": [],
            "challenges": []
        }
        
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        for json_file in self.inbox_path.glob(f"{member_name}_*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                # é…åˆ—ã®å ´åˆã¯å„è¦ç´ ã‚’å‡¦ç†
                if isinstance(data, list):
                    for item in data:
                        self._process_data_item(item, year, month, monthly_data)
                else:
                    self._process_data_item(data, year, month, monthly_data)
                    
            except Exception as e:
                logger.error(f"Error reading {json_file}: {e}")
        
        # æœˆæ¬¡åˆ†æã‚’å®Ÿè¡Œ
        analysis = self._perform_monthly_analysis(monthly_data, member_name, year, month)
        
        return analysis
    
    def _process_data_item(self, item: Dict, year: int, month: int, monthly_data: Dict):
        """å€‹åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¤ãƒ†ãƒ ã‚’å‡¦ç†"""
        try:
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡º
            timestamp = item.get("timestamp", "")
            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            
            # è©²å½“æœˆã®ãƒ‡ãƒ¼ã‚¿ã®ã¿å‡¦ç†
            if dt.year != year or dt.month != month:
                return
            
            content = item.get("content", "")
            data_type = item.get("type", "")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦åˆ†é¡
            if data_type == "daily_report":
                monthly_data["daily_reports"].append(item)
                
                # ç¨¼åƒæ™‚é–“ã‚’æŠ½å‡º
                hours_match = re.search(r'(\d+\.?\d*)\s*æ™‚é–“', content)
                if hours_match:
                    monthly_data["working_hours"].append(float(hours_match.group(1)))
                
                # å£²ä¸Šã‚’æŠ½å‡º
                revenue_match = re.search(r'(\d+(?:,\d{3})*)\s*å††', content)
                if revenue_match:
                    revenue = int(revenue_match.group(1).replace(",", ""))
                    monthly_data["revenues"].append(revenue)
                
                # å–¶æ¥­æ´»å‹•ã‚’æŠ½å‡º
                sales_match = re.search(r'å–¶æ¥­.*?(\d+)\s*ä»¶', content)
                if sales_match:
                    monthly_data["sales_activities"].append(int(sales_match.group(1)))
                
                # å®Œäº†ã‚¿ã‚¹ã‚¯ã‚’æŠ½å‡º
                if "å®Œäº†" in content or "ã§ãã¾ã—ãŸ" in content:
                    monthly_data["completed_tasks"].append(content)
                
                # èª²é¡Œã‚’æŠ½å‡º
                if "èª²é¡Œ" in content or "å›°ã£ãŸ" in content:
                    monthly_data["challenges"].append(content)
                    
            elif data_type == "question":
                monthly_data["questions"].append(item)
                
            elif data_type == "progress":
                monthly_data["progress"].append(item)
                
        except Exception as e:
            logger.error(f"Error processing data item: {e}")
    
    def _perform_monthly_analysis(self, data: Dict, member_name: str, year: int, month: int) -> Dict:
        """æœˆæ¬¡åˆ†æã‚’å®Ÿè¡Œ"""
        
        # åŸºæœ¬çµ±è¨ˆ
        total_working_hours = sum(data["working_hours"])
        avg_working_hours = sum(data["working_hours"]) / len(data["working_hours"]) if data["working_hours"] else 0
        total_revenue = sum(data["revenues"])
        total_sales = sum(data["sales_activities"])
        
        # PDCAåˆ†æ
        pdca_analysis = self._analyze_pdca(data, total_working_hours, total_revenue, total_sales)
        
        # æˆé•·æŒ‡æ¨™
        growth_metrics = self._calculate_growth_metrics(data, member_name, year, month)
        
        return {
            "member_name": member_name,
            "year": year,
            "month": month,
            "summary": {
                "total_working_hours": total_working_hours,
                "average_daily_hours": avg_working_hours,
                "total_revenue": total_revenue,
                "total_sales_activities": total_sales,
                "daily_report_count": len(data["daily_reports"]),
                "question_count": len(data["questions"]),
                "progress_count": len(data["progress"])
            },
            "pdca_analysis": pdca_analysis,
            "growth_metrics": growth_metrics,
            "raw_data": data
        }
    
    def _analyze_pdca(self, data: Dict, working_hours: float, revenue: int, sales: int) -> Dict:
        """PDCAã‚µã‚¤ã‚¯ãƒ«ã®åˆ†æ"""
        
        pdca = {
            "plan": {
                "ç›®æ¨™é”æˆåº¦": self._calculate_goal_achievement(working_hours, revenue),
                "è¨ˆç”»ã®å…·ä½“æ€§": self._analyze_plan_quality(data["daily_reports"]),
                "æ”¹å–„ãƒã‚¤ãƒ³ãƒˆ": []
            },
            "do": {
                "å®Ÿè¡Œç‡": self._calculate_execution_rate(data),
                "ç¨¼åƒåŠ¹ç‡": revenue / working_hours if working_hours > 0 else 0,
                "å–¶æ¥­åŠ¹ç‡": sales / len(data["daily_reports"]) if data["daily_reports"] else 0,
                "å¼·ã¿": [],
                "èª²é¡Œ": []
            },
            "check": {
                "æŒ¯ã‚Šè¿”ã‚Šé »åº¦": self._analyze_review_frequency(data["daily_reports"]),
                "èª²é¡Œèªè­˜åŠ›": len(data["challenges"]),
                "è³ªå•ç©æ¥µæ€§": len(data["questions"]),
                "æ°—ã¥ã": []
            },
            "action": {
                "æ”¹å–„å®Ÿæ–½æ•°": self._count_improvements(data),
                "æ¬¡æœˆã¸ã®ææ¡ˆ": [],
                "å¿…è¦ãªã‚µãƒãƒ¼ãƒˆ": []
            }
        }
        
        # å…·ä½“çš„ãªåˆ†æ
        pdca["plan"]["æ”¹å–„ãƒã‚¤ãƒ³ãƒˆ"] = self._suggest_plan_improvements(data)
        pdca["do"]["å¼·ã¿"] = self._identify_strengths(data)
        pdca["do"]["èª²é¡Œ"] = self._identify_challenges(data)
        pdca["check"]["æ°—ã¥ã"] = self._extract_insights(data)
        pdca["action"]["æ¬¡æœˆã¸ã®ææ¡ˆ"] = self._generate_suggestions(pdca)
        pdca["action"]["å¿…è¦ãªã‚µãƒãƒ¼ãƒˆ"] = self._identify_support_needs(data)
        
        return pdca
    
    def _calculate_goal_achievement(self, hours: float, revenue: int) -> float:
        """ç›®æ¨™é”æˆåº¦ã‚’è¨ˆç®—ï¼ˆä»®ã®ç›®æ¨™å€¤ï¼‰"""
        # ç›®æ¨™: æœˆ160æ™‚é–“ã€æœˆ30ä¸‡å††
        hour_achievement = min(hours / 160 * 100, 100) if hours > 0 else 0
        revenue_achievement = min(revenue / 300000 * 100, 100) if revenue > 0 else 0
        return (hour_achievement + revenue_achievement) / 2
    
    def _analyze_plan_quality(self, reports: List[Dict]) -> str:
        """è¨ˆç”»ã®å…·ä½“æ€§ã‚’åˆ†æ"""
        specific_keywords = ["æ™‚é–“", "ä»¶", "å††", "ã¾ã§", "å®Œäº†"]
        specific_count = sum(
            1 for report in reports 
            if any(keyword in report.get("content", "") for keyword in specific_keywords)
        )
        
        ratio = specific_count / len(reports) if reports else 0
        
        if ratio > 0.7:
            return "é«˜ã„ï¼ˆå…·ä½“çš„ãªæ•°å€¤ç›®æ¨™ã‚ã‚Šï¼‰"
        elif ratio > 0.4:
            return "ä¸­ç¨‹åº¦ï¼ˆä¸€éƒ¨å…·ä½“çš„ï¼‰"
        else:
            return "ä½ã„ï¼ˆæŠ½è±¡çš„ãªç›®æ¨™ãŒå¤šã„ï¼‰"
    
    def _calculate_execution_rate(self, data: Dict) -> float:
        """å®Ÿè¡Œç‡ã‚’è¨ˆç®—"""
        if not data["daily_reports"]:
            return 0
        
        # äºˆå®šã«å¯¾ã™ã‚‹å®Œäº†ã®å‰²åˆã‚’æ¨å®š
        completed = len(data["completed_tasks"])
        total_planned = len(data["daily_reports"]) * 3  # 1æ—¥å¹³å‡3ã‚¿ã‚¹ã‚¯ã¨ä»®å®š
        
        return min(completed / total_planned * 100, 100) if total_planned > 0 else 0
    
    def _analyze_review_frequency(self, reports: List[Dict]) -> str:
        """æŒ¯ã‚Šè¿”ã‚Šé »åº¦ã‚’åˆ†æ"""
        review_keywords = ["æŒ¯ã‚Šè¿”ã‚Š", "åçœ", "æ”¹å–„", "æ¬¡å›", "å­¦ã³"]
        review_count = sum(
            1 for report in reports
            if any(keyword in report.get("content", "") for keyword in review_keywords)
        )
        
        ratio = review_count / len(reports) if reports else 0
        
        if ratio > 0.5:
            return "é«˜ã„ï¼ˆå®šæœŸçš„ãªæŒ¯ã‚Šè¿”ã‚Šã‚ã‚Šï¼‰"
        elif ratio > 0.2:
            return "ä¸­ç¨‹åº¦ï¼ˆæ™‚ã€…æŒ¯ã‚Šè¿”ã‚Šï¼‰"
        else:
            return "ä½ã„ï¼ˆæŒ¯ã‚Šè¿”ã‚Šä¸è¶³ï¼‰"
    
    def _count_improvements(self, data: Dict) -> int:
        """æ”¹å–„å®Ÿæ–½æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        improvement_keywords = ["æ”¹å–„", "å¤‰æ›´", "ä¿®æ­£", "åŠ¹ç‡åŒ–", "å·¥å¤«"]
        count = 0
        
        for report in data["daily_reports"] + data["progress"]:
            content = report.get("content", "")
            if any(keyword in content for keyword in improvement_keywords):
                count += 1
        
        return count
    
    def _suggest_plan_improvements(self, data: Dict) -> List[str]:
        """è¨ˆç”»ã®æ”¹å–„ãƒã‚¤ãƒ³ãƒˆã‚’ææ¡ˆ"""
        suggestions = []
        
        if not data["working_hours"]:
            suggestions.append("ç¨¼åƒæ™‚é–“ã®è¨˜éŒ²ã‚’æ¯æ—¥è¡Œã†")
        
        if len(data["daily_reports"]) < 20:
            suggestions.append("æ—¥å ±ã®æŠ•ç¨¿é »åº¦ã‚’ä¸Šã’ã‚‹ï¼ˆç›®æ¨™ï¼šæ¯æ—¥ï¼‰")
        
        if not data["revenues"]:
            suggestions.append("å£²ä¸Šç›®æ¨™ã¨å®Ÿç¸¾ã‚’æ˜è¨˜ã™ã‚‹")
        
        return suggestions
    
    def _identify_strengths(self, data: Dict) -> List[str]:
        """å¼·ã¿ã‚’ç‰¹å®š"""
        strengths = []
        
        if data["working_hours"] and sum(data["working_hours"]) / len(data["working_hours"]) > 5:
            strengths.append("å®‰å®šã—ãŸç¨¼åƒæ™‚é–“ã®ç¢ºä¿")
        
        if len(data["questions"]) > 5:
            strengths.append("ç©æ¥µçš„ãªè³ªå•å§¿å‹¢")
        
        if data["sales_activities"] and sum(data["sales_activities"]) > 200:
            strengths.append("å–¶æ¥­æ´»å‹•ã®ç¶™ç¶šæ€§")
        
        return strengths
    
    def _identify_challenges(self, data: Dict) -> List[str]:
        """èª²é¡Œã‚’ç‰¹å®š"""
        challenges = []
        
        # ç›´æ¥çš„ãªèª²é¡Œã®æŠ½å‡º
        for item in data["challenges"]:
            # æœ€åˆã®æ•°èªã‚’æŠ½å‡º
            match = re.search(r'èª²é¡Œ[:ï¼š]?\s*(.{10,50})', item)
            if match:
                challenges.append(match.group(1))
        
        return list(set(challenges))[:5]  # é‡è¤‡ã‚’é™¤ã„ã¦æœ€å¤§5å€‹
    
    def _extract_insights(self, data: Dict) -> List[str]:
        """æ°—ã¥ãã‚’æŠ½å‡º"""
        insights = []
        
        # é€²æ—å ±å‘Šã‹ã‚‰å­¦ã³ã‚’æŠ½å‡º
        for progress in data["progress"]:
            content = progress.get("content", "")
            if "å­¦ã³" in content or "æ°—ã¥ã" in content or "ã‚ã‹ã£ãŸ" in content:
                # è©²å½“éƒ¨åˆ†ã‚’æŠ½å‡º
                match = re.search(r'(?:å­¦ã³|æ°—ã¥ã|ã‚ã‹ã£ãŸ)[:ï¼š]?\s*(.{10,50})', content)
                if match:
                    insights.append(match.group(1))
        
        return list(set(insights))[:5]
    
    def _generate_suggestions(self, pdca: Dict) -> List[str]:
        """æ¬¡æœˆã¸ã®ææ¡ˆã‚’ç”Ÿæˆ"""
        suggestions = []
        
        # ç›®æ¨™é”æˆåº¦ã«åŸºã¥ãææ¡ˆ
        achievement = pdca["plan"]["ç›®æ¨™é”æˆåº¦"]
        if achievement < 50:
            suggestions.append("å°ã•ãªç›®æ¨™ã‹ã‚‰å§‹ã‚ã¦æˆåŠŸä½“é¨“ã‚’ç©ã‚€")
        elif achievement < 80:
            suggestions.append("ç›®æ¨™ã‚’10-20%ä¸Šæ–¹ä¿®æ­£ã—ã¦ãƒãƒ£ãƒ¬ãƒ³ã‚¸")
        
        # å®Ÿè¡Œç‡ã«åŸºã¥ãææ¡ˆ
        if pdca["do"]["å®Ÿè¡Œç‡"] < 60:
            suggestions.append("ã‚¿ã‚¹ã‚¯ã®å„ªå…ˆé †ä½ã‚’æ˜ç¢ºã«ã™ã‚‹")
        
        # åŠ¹ç‡ã«åŸºã¥ãææ¡ˆ
        if pdca["do"]["ç¨¼åƒåŠ¹ç‡"] < 2000:  # æ™‚çµ¦2000å††æœªæº€
            suggestions.append("é«˜å˜ä¾¡æ¡ˆä»¶ã®ç²å¾—ã«æ³¨åŠ›")
        
        return suggestions
    
    def _identify_support_needs(self, data: Dict) -> List[str]:
        """å¿…è¦ãªã‚µãƒãƒ¼ãƒˆã‚’ç‰¹å®š"""
        needs = []
        
        # è³ªå•å†…å®¹ã‹ã‚‰åˆ¤æ–­
        tech_questions = sum(1 for q in data["questions"] if any(
            tech in q.get("content", "").lower() 
            for tech in ["å®Ÿè£…", "ã‚¨ãƒ©ãƒ¼", "ã‚³ãƒ¼ãƒ‰", "ãƒã‚°"]
        ))
        
        if tech_questions > 3:
            needs.append("æŠ€è¡“çš„ãªãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°")
        
        if len(data["questions"]) > 10:
            needs.append("å®šæœŸçš„ãª1on1ã‚»ãƒƒã‚·ãƒ§ãƒ³")
        
        if not data["revenues"]:
            needs.append("å–¶æ¥­ãƒ»æ¡ˆä»¶ç²å¾—ã®ã‚µãƒãƒ¼ãƒˆ")
        
        return needs
    
    def _calculate_growth_metrics(self, data: Dict, member_name: str, year: int, month: int) -> Dict:
        """æˆé•·æŒ‡æ¨™ã‚’è¨ˆç®—"""
        # å‰æœˆã®ãƒ‡ãƒ¼ã‚¿ã¨æ¯”è¼ƒï¼ˆç°¡æ˜“ç‰ˆï¼‰
        prev_month = month - 1 if month > 1 else 12
        prev_year = year if month > 1 else year - 1
        
        return {
            "ç¨¼åƒæ™‚é–“æˆé•·ç‡": 0,  # TODO: å‰æœˆãƒ‡ãƒ¼ã‚¿ã¨ã®æ¯”è¼ƒ
            "å£²ä¸Šæˆé•·ç‡": 0,
            "å–¶æ¥­åŠ¹ç‡æ”¹å–„ç‡": 0,
            "ã‚¹ã‚­ãƒ«ç¿’å¾—æ•°": len(set(self._extract_technologies(data))),
            "èª²é¡Œè§£æ±ºç‡": self._calculate_resolution_rate(data)
        }
    
    def _extract_technologies(self, data: Dict) -> List[str]:
        """ä½¿ç”¨æŠ€è¡“ã‚’æŠ½å‡º"""
        tech_keywords = [
            "JavaScript", "TypeScript", "React", "Vue", "WordPress",
            "HTML", "CSS", "Git", "AI", "ChatGPT", "Python"
        ]
        
        found_techs = set()
        for item in data["daily_reports"] + data["progress"]:
            content = item.get("content", "").lower()
            for tech in tech_keywords:
                if tech.lower() in content:
                    found_techs.add(tech)
        
        return list(found_techs)
    
    def _calculate_resolution_rate(self, data: Dict) -> float:
        """èª²é¡Œè§£æ±ºç‡ã‚’è¨ˆç®—"""
        if not data["challenges"]:
            return 100.0
        
        # è§£æ±ºæ¸ˆã¿ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        resolved_keywords = ["è§£æ±º", "ã§ããŸ", "å…‹æœ", "æ”¹å–„ã—ãŸ"]
        resolved_count = sum(
            1 for challenge in data["challenges"]
            if any(keyword in challenge for keyword in resolved_keywords)
        )
        
        return (resolved_count / len(data["challenges"]) * 100) if data["challenges"] else 0
    
    def generate_monthly_report(self, analysis: Dict) -> str:
        """æœˆå ±ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’ç”Ÿæˆ"""
        member = analysis["member_name"]
        year = analysis["year"]
        month = analysis["month"]
        summary = analysis["summary"]
        pdca = analysis["pdca_analysis"]
        growth = analysis["growth_metrics"]
        
        md = f"""# {member} - {year}å¹´{month}æœˆ æœˆå ±

## ğŸ“Š æœˆæ¬¡ã‚µãƒãƒªãƒ¼

### æ´»å‹•å®Ÿç¸¾
- **ç·ç¨¼åƒæ™‚é–“**: {summary['total_working_hours']:.1f}æ™‚é–“
- **å¹³å‡ç¨¼åƒæ™‚é–“**: {summary['average_daily_hours']:.1f}æ™‚é–“/æ—¥
- **ç·å£²ä¸Š**: {summary['total_revenue']:,}å††
- **å–¶æ¥­æ´»å‹•**: {summary['total_sales_activities']}ä»¶
- **æ—¥å ±æŠ•ç¨¿æ•°**: {summary['daily_report_count']}å›
- **è³ªå•æ•°**: {summary['question_count']}ä»¶
- **é€²æ—å ±å‘Š**: {summary['progress_count']}ä»¶

### åŠ¹ç‡æŒ‡æ¨™
- **æ™‚çµ¦æ›ç®—**: {int(summary['total_revenue'] / summary['total_working_hours']) if summary['total_working_hours'] > 0 else 0:,}å††/æ™‚é–“
- **å–¶æ¥­åŠ¹ç‡**: {summary['total_sales_activities'] / summary['daily_report_count'] if summary['daily_report_count'] > 0 else 0:.1f}ä»¶/æ—¥

## ğŸ”„ PDCAåˆ†æ

### Planï¼ˆè¨ˆç”»ï¼‰
- **ç›®æ¨™é”æˆåº¦**: {pdca['plan']['ç›®æ¨™é”æˆåº¦']:.1f}%
- **è¨ˆç”»ã®å…·ä½“æ€§**: {pdca['plan']['è¨ˆç”»ã®å…·ä½“æ€§']}

#### æ”¹å–„ãƒã‚¤ãƒ³ãƒˆ
"""
        
        for point in pdca['plan']['æ”¹å–„ãƒã‚¤ãƒ³ãƒˆ']:
            md += f"- {point}\n"
        
        md += f"""
### Doï¼ˆå®Ÿè¡Œï¼‰
- **å®Ÿè¡Œç‡**: {pdca['do']['å®Ÿè¡Œç‡']:.1f}%
- **ç¨¼åƒåŠ¹ç‡**: {pdca['do']['ç¨¼åƒåŠ¹ç‡']:.0f}å††/æ™‚é–“
- **å–¶æ¥­åŠ¹ç‡**: {pdca['do']['å–¶æ¥­åŠ¹ç‡']:.1f}ä»¶/æ—¥

#### å¼·ã¿
"""
        
        for strength in pdca['do']['å¼·ã¿']:
            md += f"- âœ… {strength}\n"
        
        md += "\n#### èª²é¡Œ\n"
        for challenge in pdca['do']['èª²é¡Œ']:
            md += f"- âš ï¸ {challenge}\n"
        
        md += f"""
### Checkï¼ˆè©•ä¾¡ï¼‰
- **æŒ¯ã‚Šè¿”ã‚Šé »åº¦**: {pdca['check']['æŒ¯ã‚Šè¿”ã‚Šé »åº¦']}
- **èª²é¡Œèªè­˜åŠ›**: {pdca['check']['èª²é¡Œèªè­˜åŠ›']}ä»¶ã®èª²é¡Œã‚’èªè­˜
- **è³ªå•ç©æ¥µæ€§**: {pdca['check']['è³ªå•ç©æ¥µæ€§']}ä»¶ã®è³ªå•

#### ä¸»ãªæ°—ã¥ã
"""
        
        for insight in pdca['check']['æ°—ã¥ã']:
            md += f"- ğŸ’¡ {insight}\n"
        
        md += f"""
### Actionï¼ˆæ”¹å–„ï¼‰
- **æ”¹å–„å®Ÿæ–½æ•°**: {pdca['action']['æ”¹å–„å®Ÿæ–½æ•°']}ä»¶

#### æ¬¡æœˆã¸ã®ææ¡ˆ
"""
        
        for suggestion in pdca['action']['æ¬¡æœˆã¸ã®ææ¡ˆ']:
            md += f"- ğŸ¯ {suggestion}\n"
        
        md += "\n#### å¿…è¦ãªã‚µãƒãƒ¼ãƒˆ\n"
        for support in pdca['action']['å¿…è¦ãªã‚µãƒãƒ¼ãƒˆ']:
            md += f"- ğŸ¤ {support}\n"
        
        md += f"""
## ğŸ“ˆ æˆé•·æŒ‡æ¨™

- **ã‚¹ã‚­ãƒ«ç¿’å¾—æ•°**: {growth['ã‚¹ã‚­ãƒ«ç¿’å¾—æ•°']}å€‹ã®æŠ€è¡“ã«è§¦ã‚ŒãŸ
- **èª²é¡Œè§£æ±ºç‡**: {growth['èª²é¡Œè§£æ±ºç‡']:.1f}%

## ğŸ’­ ã‚³ãƒ¼ãƒãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆ

1. **ç¶™ç¶šã™ã¹ãç‚¹**
   - æ—¥ã€…ã®æ´»å‹•è¨˜éŒ²ã®ç¿’æ…£
   - ç©æ¥µçš„ãªè³ªå•å§¿å‹¢
   - å–¶æ¥­æ´»å‹•ã®ç¶™ç¶š

2. **æ”¹å–„ã™ã¹ãç‚¹**
   - ç›®æ¨™è¨­å®šã®å…·ä½“åŒ–
   - æŒ¯ã‚Šè¿”ã‚Šã®æ·±æ˜ã‚Š
   - åŠ¹ç‡æ€§ã®å‘ä¸Š

3. **æ¬¡æœˆã®ãƒ•ã‚©ãƒ¼ã‚«ã‚¹**
   - é«˜å˜ä¾¡æ¡ˆä»¶ã®ç²å¾—
   - ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ã®æ™‚é–“ç¢ºä¿
   - PDCAã‚µã‚¤ã‚¯ãƒ«ã®é«˜é€ŸåŒ–

---
*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™ã€‚è©³ç´°ãªå€‹åˆ¥ç›¸è«‡ãŒå¿…è¦ãªå ´åˆã¯ãŠç”³ã—å‡ºãã ã•ã„ã€‚*
"""
        
        return md
    
    def _process_notion_links(self, member: str, year: int, month: int, analysis: Dict):
        """æœˆå ±å†…ã®Notionãƒªãƒ³ã‚¯ã‚’å‡¦ç†"""
        if not self.notion or not self.notion.client:
            logger.info("Notion APIãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒªãƒ³ã‚¯å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return
        
        # å…¨æ—¥å ±ã‹ã‚‰Notionãƒªãƒ³ã‚¯ã‚’æŠ½å‡º
        notion_links = []
        all_content = ""
        
        # æ—¥å ±ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åé›†
        for report in analysis.get('raw_data', {}).get('daily_reports', []):
            if 'content' in report:
                all_content += report['content'] + "\n"
        
        # è³ªå•ã‹ã‚‰ã‚‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åé›†
        for question in analysis.get('raw_data', {}).get('questions', []):
            if 'content' in question:
                all_content += question['content'] + "\n"
        
        # Notionãƒªãƒ³ã‚¯ã‚’æŠ½å‡ºã—ã¦å‡¦ç†
        extracted_links = self.notion.extract_notion_links(all_content)
        
        if extracted_links:
            logger.info(f"{member}ã®æœˆå ±ã‹ã‚‰{len(extracted_links)}å€‹ã®Notionãƒªãƒ³ã‚¯ã‚’æ¤œå‡º")
            
            # Notionã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
            notion_data = []
            for link_info in extracted_links:
                try:
                    page_content = self.notion.get_page_content(link_info['page_id'])
                    if page_content:
                        notion_data.append({
                            'original_url': link_info['url'],
                            'page_data': page_content,
                            'extracted_at': datetime.now().isoformat()
                        })
                except Exception as e:
                    logger.error(f"Notionãƒšãƒ¼ã‚¸å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒ¡ãƒ³ãƒãƒ¼ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜
            if notion_data:
                self.notion.save_notion_content(member, notion_data, 
                                              str(self.support_path / "ãƒ¡ãƒ³ãƒãƒ¼ç®¡ç†"))
    
    def save_monthly_report(self, analysis: Dict):
        """æœˆå ±ã‚’ä¿å­˜"""
        member = analysis["member_name"]
        year = analysis["year"]
        month = analysis["month"]
        
        # ãƒ¡ãƒ³ãƒãƒ¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        member_dir = self.members_path / member
        member_dir.mkdir(exist_ok=True)
        
        # æœˆå ±ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        monthly_dir = member_dir / "æœˆå ±"
        monthly_dir.mkdir(exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        filename = f"{year}å¹´{month:02d}æœˆ_æœˆå ±.md"
        filepath = monthly_dir / filename
        
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ç”Ÿæˆ
        content = self.generate_monthly_report(analysis)
        
        # ä¿å­˜
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info(f"Saved monthly report: {filepath}")
        
        # Notionãƒªãƒ³ã‚¯ã‚’å‡¦ç†
        self._process_notion_links(member, year, month, analysis)
        
        return filepath

def process_all_members_monthly(year: int, month: int):
    """å…¨ãƒ¡ãƒ³ãƒãƒ¼ã®æœˆå ±ã‚’å‡¦ç†"""
    analyzer = MonthlyReportAnalyzer()
    
    # ãƒ¡ãƒ³ãƒãƒ¼ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆJSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ¨å®šï¼‰
    members = set()
    for json_file in analyzer.inbox_path.glob("*_*.json"):
        member_name = json_file.stem.split("_")[0]
        members.add(member_name)
    
    processed = []
    for member in members:
        logger.info(f"Processing {member} for {year}/{month}...")
        
        # åˆ†æå®Ÿè¡Œ
        analysis = analyzer.analyze_member_monthly_data(member, year, month)
        
        # æœˆå ±ä¿å­˜
        if analysis["summary"]["daily_report_count"] > 0:
            filepath = analyzer.save_monthly_report(analysis)
            processed.append({
                "member": member,
                "filepath": filepath,
                "summary": analysis["summary"]
            })
    
    return processed

if __name__ == "__main__":
    # ç¾åœ¨ã®å¹´æœˆã§å®Ÿè¡Œ
    now = datetime.now()
    year = now.year
    month = now.month
    
    # å¼•æ•°ã§å¹´æœˆã‚’æŒ‡å®šå¯èƒ½
    import sys
    if len(sys.argv) > 2:
        year = int(sys.argv[1])
        month = int(sys.argv[2])
    
    print(f"ğŸ“Š {year}å¹´{month}æœˆã®æœˆå ±ã‚’ç”Ÿæˆã—ã¾ã™...")
    
    results = process_all_members_monthly(year, month)
    
    print(f"\nâœ… å®Œäº†: {len(results)}åã®æœˆå ±ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
    for result in results:
        print(f"  - {result['member']}: {result['filepath']}")