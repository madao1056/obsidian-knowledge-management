#!/usr/bin/env python3
"""
Discordæ—¥å ±è§£æã‚·ã‚¹ãƒ†ãƒ 
æ—¥å ±ã‹ã‚‰æ§‹é€ åŒ–æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ObsidianãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã«å¤‰æ›
"""

import json
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DailyReportAnalyzer:
    def __init__(self):
        self.inbox_path = Path(__file__).parent.parent / "00_Inbox" / "discord"
        self.support_path = Path(__file__).parent.parent / "03_Support" / "ã‚°ãƒƒã‚µãƒãƒ»ãƒ©ãƒœ"
        self.members_path = self.support_path / "ãƒ¡ãƒ³ãƒãƒ¼ç®¡ç†"
        self.members_path.mkdir(parents=True, exist_ok=True)
        
        # æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.patterns = {
            "working_hours": re.compile(r'(?:ç¨¼åƒ|ä½œæ¥­|æ´»å‹•).*?(\d+\.?\d*)\s*(?:æ™‚é–“|h)', re.IGNORECASE),
            "tasks_completed": re.compile(r'(?:å®Œäº†|çµ‚äº†|ã§ããŸ|ã—ãŸ).*?[:ï¼š](.+?)(?:\n|$)', re.MULTILINE),
            "tasks_planned": re.compile(r'(?:äºˆå®š|ã‚„ã‚‹|ã™ã‚‹).*?[:ï¼š](.+?)(?:\n|$)', re.MULTILINE),
            "challenges": re.compile(r'(?:èª²é¡Œ|å•é¡Œ|å›°ã£ãŸ|è©°ã¾ã£ãŸ).*?[:ï¼š](.+?)(?:\n|$)', re.MULTILINE),
            "revenue": re.compile(r'(?:å£²ä¸Š|åå…¥|å ±é…¬).*?(\d+(?:,\d{3})*)\s*å††', re.IGNORECASE),
            "projects": re.compile(r'(?:æ¡ˆä»¶|ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ|åˆ¶ä½œ).*?[:ï¼š](.+?)(?:\n|$)', re.MULTILINE),
            "å–¶æ¥­": re.compile(r'å–¶æ¥­.*?(\d+)\s*ä»¶', re.IGNORECASE)
        }
    
    def analyze_report(self, report_data: Dict) -> Dict:
        """æ—¥å ±ã‚’è§£æã—ã¦æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        content = report_data.get("content", "")
        author = report_data.get("author", "unknown")
        date = report_data.get("date", datetime.now().strftime("%Y-%m-%d"))
        
        # ç¨¼åƒæ™‚é–“ã®æŠ½å‡º
        working_hours = self._extract_working_hours(content)
        
        # ã‚¿ã‚¹ã‚¯æƒ…å ±ã®æŠ½å‡º
        tasks_completed = self._extract_tasks(content, "completed")
        tasks_planned = self._extract_tasks(content, "planned")
        
        # èª²é¡Œãƒ»å•é¡Œã®æŠ½å‡º
        challenges = self._extract_challenges(content)
        
        # å£²ä¸Šæƒ…å ±ã®æŠ½å‡º
        revenue = self._extract_revenue(content)
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã®æŠ½å‡º
        projects = self._extract_projects(content)
        
        # å–¶æ¥­æ´»å‹•ã®æŠ½å‡º
        sales_activities = self._extract_sales_activities(content)
        
        # æ„Ÿæƒ…åˆ†æï¼ˆç°¡æ˜“ç‰ˆï¼‰
        sentiment = self._analyze_sentiment(content)
        
        return {
            "author": author,
            "date": date,
            "working_hours": working_hours,
            "tasks_completed": tasks_completed,
            "tasks_planned": tasks_planned,
            "challenges": challenges,
            "revenue": revenue,
            "projects": projects,
            "sales_activities": sales_activities,
            "sentiment": sentiment,
            "raw_content": content
        }
    
    def _extract_working_hours(self, content: str) -> Optional[float]:
        """ç¨¼åƒæ™‚é–“ã‚’æŠ½å‡º"""
        matches = self.patterns["working_hours"].findall(content)
        if matches:
            try:
                return float(matches[0])
            except ValueError:
                pass
        return None
    
    def _extract_tasks(self, content: str, task_type: str) -> List[str]:
        """ã‚¿ã‚¹ã‚¯ã‚’æŠ½å‡º"""
        pattern = self.patterns[f"tasks_{task_type}"]
        matches = pattern.findall(content)
        tasks = []
        for match in matches:
            # ç®‡æ¡æ›¸ãã‚„ç•ªå·ä»˜ããƒªã‚¹ãƒˆã‚’åˆ†å‰²
            items = re.split(r'[ãƒ»\n]\s*', match)
            tasks.extend([item.strip() for item in items if item.strip()])
        return tasks
    
    def _extract_challenges(self, content: str) -> List[str]:
        """èª²é¡Œãƒ»å•é¡Œã‚’æŠ½å‡º"""
        matches = self.patterns["challenges"].findall(content)
        challenges = []
        for match in matches:
            items = re.split(r'[ãƒ»\n]\s*', match)
            challenges.extend([item.strip() for item in items if item.strip()])
        return challenges
    
    def _extract_revenue(self, content: str) -> Optional[int]:
        """å£²ä¸Šæƒ…å ±ã‚’æŠ½å‡º"""
        matches = self.patterns["revenue"].findall(content)
        if matches:
            try:
                # ã‚«ãƒ³ãƒã‚’é™¤å»ã—ã¦æ•°å€¤ã«å¤‰æ›
                return int(matches[0].replace(",", ""))
            except ValueError:
                pass
        return None
    
    def _extract_projects(self, content: str) -> List[str]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‚’æŠ½å‡º"""
        matches = self.patterns["projects"].findall(content)
        projects = []
        for match in matches:
            items = re.split(r'[ãƒ»\n]\s*', match)
            projects.extend([item.strip() for item in items if item.strip()])
        return projects
    
    def _extract_sales_activities(self, content: str) -> Optional[int]:
        """å–¶æ¥­æ´»å‹•ä»¶æ•°ã‚’æŠ½å‡º"""
        matches = self.patterns["å–¶æ¥­"].findall(content)
        if matches:
            try:
                return int(matches[0])
            except ValueError:
                pass
        return None
    
    def _analyze_sentiment(self, content: str) -> str:
        """æ„Ÿæƒ…åˆ†æï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        positive_words = ["å®Œäº†", "é”æˆ", "ã§ããŸ", "è‰¯ã‹ã£ãŸ", "å¬‰ã—ã„", "é †èª¿"]
        negative_words = ["å›°ã£ãŸ", "è©°ã¾ã£ãŸ", "é›£ã—ã„", "å³ã—ã„", "å¤§å¤‰", "ç–²ã‚Œ"]
        
        positive_count = sum(1 for word in positive_words if word in content)
        negative_count = sum(1 for word in negative_words if word in content)
        
        if positive_count > negative_count:
            return "positive"
        elif negative_count > positive_count:
            return "negative"
        else:
            return "neutral"
    
    def save_to_obsidian(self, analysis: Dict):
        """è§£æçµæœã‚’Obsidianå½¢å¼ã§ä¿å­˜"""
        author = analysis["author"]
        date = analysis["date"]
        
        # ãƒ¡ãƒ³ãƒãƒ¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        member_dir = self.members_path / author
        member_dir.mkdir(exist_ok=True)
        
        # æ—¥å ±ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        daily_reports_dir = member_dir / "æ—¥å ±"
        daily_reports_dir.mkdir(exist_ok=True)
        
        # æ—¥å ±ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        report_path = daily_reports_dir / f"{date}_æ—¥å ±.md"
        
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§ä¿å­˜
        content = self._generate_markdown(analysis)
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        # ãƒ¡ãƒ³ãƒãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
        self._update_member_profile(author, analysis)
        
        logger.info(f"Saved daily report: {report_path}")
        return report_path
    
    def _generate_markdown(self, analysis: Dict) -> str:
        """è§£æçµæœã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã«å¤‰æ›"""
        md = f"# æ—¥å ± - {analysis['author']}\n"
        md += f"## {analysis['date']}\n\n"
        
        # ç¨¼åƒæ™‚é–“
        if analysis["working_hours"]:
            md += f"### ç¨¼åƒæ™‚é–“\n"
            md += f"- {analysis['working_hours']}æ™‚é–“\n\n"
        
        # å®Œäº†ã‚¿ã‚¹ã‚¯
        if analysis["tasks_completed"]:
            md += f"### å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯\n"
            for task in analysis["tasks_completed"]:
                md += f"- {task}\n"
            md += "\n"
        
        # äºˆå®šã‚¿ã‚¹ã‚¯
        if analysis["tasks_planned"]:
            md += f"### äºˆå®šã—ã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯\n"
            for task in analysis["tasks_planned"]:
                md += f"- {task}\n"
            md += "\n"
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
        if analysis["projects"]:
            md += f"### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ»æ¡ˆä»¶\n"
            for project in analysis["projects"]:
                md += f"- {project}\n"
            md += "\n"
        
        # å–¶æ¥­æ´»å‹•
        if analysis["sales_activities"]:
            md += f"### å–¶æ¥­æ´»å‹•\n"
            md += f"- é€ä¿¡ä»¶æ•°: {analysis['sales_activities']}ä»¶\n\n"
        
        # å£²ä¸Š
        if analysis["revenue"]:
            md += f"### å£²ä¸Š\n"
            md += f"- {analysis['revenue']:,}å††\n\n"
        
        # èª²é¡Œãƒ»å›°ã£ãŸã“ã¨
        if analysis["challenges"]:
            md += f"### èª²é¡Œãƒ»å›°ã£ãŸã“ã¨\n"
            for challenge in analysis["challenges"]:
                md += f"- {challenge}\n"
            md += "\n"
        
        # æ„Ÿæƒ…çŠ¶æ…‹
        sentiment_map = {
            "positive": "ğŸ˜Š ãƒã‚¸ãƒ†ã‚£ãƒ–",
            "negative": "ğŸ˜Ÿ ãƒã‚¬ãƒ†ã‚£ãƒ–",
            "neutral": "ğŸ˜ ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«"
        }
        md += f"### æ„Ÿæƒ…çŠ¶æ…‹\n"
        md += f"- {sentiment_map.get(analysis['sentiment'], 'ä¸æ˜')}\n\n"
        
        # åŸæ–‡
        md += f"### åŸæ–‡\n"
        md += f"```\n{analysis['raw_content']}\n```\n"
        
        return md
    
    def _update_member_profile(self, author: str, analysis: Dict):
        """ãƒ¡ãƒ³ãƒãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"""
        profile_path = self.members_path / author / "ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«.md"
        
        # æ—¢å­˜ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã‹æ–°è¦ä½œæˆ
        if profile_path.exists():
            with open(profile_path, 'r', encoding='utf-8') as f:
                content = f.read()
        else:
            content = self._create_initial_profile(author)
        
        # æœ€æ–°æƒ…å ±ã‚’è¿½åŠ 
        updated_content = self._update_profile_content(content, analysis)
        
        # ä¿å­˜
        with open(profile_path, 'w', encoding='utf-8') as f:
            f.write(updated_content)
    
    def _create_initial_profile(self, author: str) -> str:
        """åˆæœŸãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return f"""# {author} ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«

## åŸºæœ¬æƒ…å ±
- åå‰: {author}
- å‚åŠ æ—¥: {datetime.now().strftime("%Y-%m-%d")}

## æ´»å‹•ã‚µãƒãƒªãƒ¼
### ç¨¼åƒæ™‚é–“
- ä»Šæœˆã®åˆè¨ˆ: 0æ™‚é–“
- å…ˆæœˆã®åˆè¨ˆ: 0æ™‚é–“
- å¹³å‡ç¨¼åƒæ™‚é–“: 0æ™‚é–“/æ—¥

### å–¶æ¥­æ´»å‹•
- ä»Šæœˆã®é€ä¿¡æ•°: 0ä»¶
- ç´¯è¨ˆé€ä¿¡æ•°: 0ä»¶
- è¿”ä¿¡ç‡: 0%

### å£²ä¸Š
- ä»Šæœˆ: 0å††
- ç´¯è¨ˆ: 0å††

## æœ€è¿‘ã®æ´»å‹•
### ç›´è¿‘ã®æ—¥å ±
- [ãƒªãƒ³ã‚¯ãªã—]

## ã‚¹ã‚­ãƒ«ãƒ»å°‚é–€åˆ†é‡
- 

## èª²é¡Œãƒ»ã‚µãƒãƒ¼ãƒˆå±¥æ­´
### ã‚ˆãã‚ã‚‹èª²é¡Œ
- 

### è§£æ±ºæ¸ˆã¿èª²é¡Œ
- 

## ãƒ¡ãƒ¢ãƒ»ç‰¹è¨˜äº‹é …
- 
"""
    
    def _update_profile_content(self, content: str, analysis: Dict) -> str:
        """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’æ›´æ–°"""
        # TODO: ã‚ˆã‚Šæ´—ç·´ã•ã‚ŒãŸæ›´æ–°ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
        # ç¾åœ¨ã¯æœ€æ–°ã®æ—¥å ±ã¸ã®ãƒªãƒ³ã‚¯ã‚’æ›´æ–°ã™ã‚‹ã ã‘
        date = analysis["date"]
        link = f"- [[{date}_æ—¥å ±]]"
        
        # ç›´è¿‘ã®æ—¥å ±ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã—ã¦æ›´æ–°
        lines = content.split('\n')
        for i, line in enumerate(lines):
            if "### ç›´è¿‘ã®æ—¥å ±" in line:
                if i + 1 < len(lines):
                    lines[i + 1] = link
                break
        
        return '\n'.join(lines)
    
    def process_all_reports(self):
        """ã™ã¹ã¦ã®æœªå‡¦ç†æ—¥å ±ã‚’å‡¦ç†"""
        json_files = list(self.inbox_path.glob("*_æ—¥å ±.json"))
        processed_count = 0
        
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    report_data = json.load(f)
                
                # è§£æ
                analysis = self.analyze_report(report_data)
                
                # Obsidianã«ä¿å­˜
                self.save_to_obsidian(analysis)
                
                # å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                json_file.unlink()
                
                processed_count += 1
                logger.info(f"Processed: {json_file.name}")
                
            except Exception as e:
                logger.error(f"Error processing {json_file}: {str(e)}")
        
        return processed_count

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    analyzer = DailyReportAnalyzer()
    count = analyzer.process_all_reports()
    print(f"å‡¦ç†å®Œäº†: {count}ä»¶ã®æ—¥å ±ã‚’å‡¦ç†ã—ã¾ã—ãŸ")