#!/usr/bin/env python3
"""
ãƒ¡ãƒ³ãƒãƒ¼ç®¡ç†ã‚’æ•´ç†ãƒ»çµ±åˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- åŒä¸€äººç‰©ï¼ˆyukari_webã¨yukariï¼‰ã‚’çµ±åˆ
- æ—¥ä»˜åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµ±åˆ
- ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã‚’ã‚·ãƒ³ãƒ—ãƒ«åŒ–
"""

import shutil
from pathlib import Path
import json
import re
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MemberConsolidator:
    def __init__(self):
        self.support_path = Path(__file__).parent.parent / "03_Support" / "ã‚°ãƒƒã‚µãƒãƒ»ãƒ©ãƒœ"
        self.members_path = self.support_path / "ãƒ¡ãƒ³ãƒãƒ¼ç®¡ç†"
        self.inbox_path = Path(__file__).parent.parent / "00_Inbox" / "discord"
        
        # åŒä¸€äººç‰©ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        self.member_mapping = {
            "yukari_web": "yukari",  # yukari_webã‚’yukariã«çµ±åˆ
            "gussan_yoshinani": "gussan",  # gussané–¢é€£ã¯é™¤å¤–
            "prog.ji": "ãƒ­ã‚°ã‚¸",
            "takanori07": "ã‚¿ã‚«ãƒãƒª"
        }
        
        # é™¤å¤–ã™ã‚‹ãƒ¡ãƒ³ãƒãƒ¼ï¼ˆgussanã¨é–¢é€£ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¯å…¨ã¦é™¤å¤–ï¼‰
        self.exclude_members = ["gussan", "gussan_yoshinani"]
        
    def consolidate_all_members(self):
        """å…¨ãƒ¡ãƒ³ãƒãƒ¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ"""
        logger.info("ãƒ¡ãƒ³ãƒãƒ¼ç®¡ç†ã®æ•´ç†ã‚’é–‹å§‹ã—ã¾ã™...")
        
        # 1. æ–°ã—ã„ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã‚’ä½œæˆ
        self._create_new_structure()
        
        # 2. JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        self._consolidate_json_data()
        
        # 3. æ—¢å­˜ã®åˆ†æ•£ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµ±åˆ
        self._consolidate_existing_files()
        
        # 4. çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        self._generate_consolidated_reports()
        
        logger.info("âœ… ãƒ¡ãƒ³ãƒãƒ¼ç®¡ç†ã®æ•´ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
    
    def _create_new_structure(self):
        """æ–°ã—ã„ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã‚’ä½œæˆ"""
        target_members = ["yukari", "ãƒ­ã‚°ã‚¸", "ã‚¿ã‚«ãƒãƒª"]
        
        for member in target_members:
            member_dir = self.members_path / member
            member_dir.mkdir(exist_ok=True)
            logger.info(f"ğŸ“ {member}ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ")
    
    def _consolidate_json_data(self):
        """JSONãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ"""
        # ãƒ¡ãƒ³ãƒãƒ¼ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
        member_data = {
            "yukari": {
                "daily_reports": [],
                "questions": [],
                "progress": [],
                "self_introductions": []
            },
            "ãƒ­ã‚°ã‚¸": {
                "daily_reports": [],
                "questions": [],
                "progress": [],
                "self_introductions": []
            },
            "ã‚¿ã‚«ãƒãƒª": {
                "daily_reports": [],
                "questions": [],
                "progress": [],
                "self_introductions": []
            }
        }
        
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§çµ±åˆ
        for json_file in self.inbox_path.glob("*.json"):
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ¡ãƒ³ãƒãƒ¼åã‚’æŠ½å‡º
                filename_parts = json_file.stem.split("_")
                if len(filename_parts) < 3:
                    continue
                    
                raw_member = filename_parts[0]
                
                # é™¤å¤–ãƒ¡ãƒ³ãƒãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆgussanã‚’å«ã‚€ï¼‰
                if raw_member in self.exclude_members or "gussan" in raw_member.lower():
                    continue
                
                # ãƒ¡ãƒ³ãƒãƒ¼åã‚’æ­£è¦åŒ–
                normalized_member = self._normalize_member_name(raw_member)
                if not normalized_member or normalized_member not in member_data:
                    continue
                
                # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
                data_type = self._determine_data_type(json_file.stem)
                
                # é…åˆ—ã®å ´åˆã¯å±•é–‹
                if isinstance(data, list):
                    member_data[normalized_member][data_type].extend(data)
                else:
                    member_data[normalized_member][data_type].append(data)
                
                logger.info(f"ğŸ“„ {json_file.name} â†’ {normalized_member}/{data_type}")
                
            except Exception as e:
                logger.error(f"ã‚¨ãƒ©ãƒ¼: {json_file} - {e}")
        
        # çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        self._save_consolidated_data(member_data)
    
    def _normalize_member_name(self, raw_name: str) -> str:
        """ãƒ¡ãƒ³ãƒãƒ¼åã‚’æ­£è¦åŒ–"""
        # gussanã¯é™¤å¤–
        if "gussan" in raw_name.lower():
            return None
        elif raw_name in ["yukari_web", "yukari"]:
            return "yukari"
        elif raw_name == "prog.ji":
            return "ãƒ­ã‚°ã‚¸"
        elif raw_name == "takanori07":
            return "ã‚¿ã‚«ãƒãƒª"
        else:
            return None
    
    def _determine_data_type(self, filename: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š"""
        if "daily_report" in filename or "æ—¥å ±" in filename:
            return "daily_reports"
        elif "question" in filename or "è³ªå•" in filename:
            return "questions"
        elif "progress" in filename or "é€²æ—" in filename:
            return "progress"
        elif "è‡ªå·±ç´¹ä»‹" in filename:
            return "self_introductions"
        else:
            return "daily_reports"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    def _save_consolidated_data(self, member_data: dict):
        """çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚’å„ãƒ¡ãƒ³ãƒãƒ¼ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜"""
        for member, data in member_data.items():
            member_dir = self.members_path / member
            
            # çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ
            self._create_member_overview(member, data)
            
            # å…¨æ´»å‹•å±¥æ­´ã‚’1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«
            self._create_activity_log(member, data)
            
            # è³ªå•é›†ã‚’ä½œæˆ
            if data["questions"]:
                self._create_question_collection(member, data["questions"])
            
            # é€²æ—è¨˜éŒ²ã‚’ä½œæˆ
            if data["progress"]:
                self._create_progress_log(member, data["progress"])
    
    def _create_member_overview(self, member: str, data: dict):
        """ãƒ¡ãƒ³ãƒãƒ¼æ¦‚è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        overview_path = self.members_path / member / f"{member}_æ¦‚è¦.md"
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
        total_reports = len(data["daily_reports"])
        total_questions = len(data["questions"])
        total_progress = len(data["progress"])
        
        # æ´»å‹•æœŸé–“ã‚’ç‰¹å®š
        all_dates = []
        for category in data.values():
            for item in category:
                if isinstance(item, dict) and "timestamp" in item:
                    try:
                        dt = datetime.fromisoformat(item["timestamp"].replace('Z', '+00:00'))
                        all_dates.append(dt)
                    except:
                        pass
        
        if all_dates:
            start_date = min(all_dates).strftime("%Yå¹´%mæœˆ%dæ—¥")
            end_date = max(all_dates).strftime("%Yå¹´%mæœˆ%dæ—¥")
        else:
            start_date = end_date = "ä¸æ˜"
        
        # æ¦‚è¦ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’ç”Ÿæˆ
        content = f"""# {member} - ãƒ¡ãƒ³ãƒãƒ¼æ¦‚è¦

## ğŸ“Š æ´»å‹•ã‚µãƒãƒªãƒ¼

### åŸºæœ¬æƒ…å ±
- **æ´»å‹•æœŸé–“**: {start_date} ã€œ {end_date}
- **ç·æ—¥å ±æ•°**: {total_reports}ä»¶
- **ç·è³ªå•æ•°**: {total_questions}ä»¶
- **é€²æ—å ±å‘Š**: {total_progress}ä»¶

### ä¸»ãªæ´»å‹•å†…å®¹
"""
        
        # æœ€è¿‘ã®æ´»å‹•ã‚’æŠ½å‡º
        recent_activities = self._extract_recent_activities(data)
        for activity in recent_activities[:5]:
            content += f"- {activity}\n"
        
        content += """
## ğŸ“ˆ æˆé•·ã®è»Œè·¡

### ã‚¹ã‚­ãƒ«ãƒ»æŠ€è¡“
"""
        # æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        tech_keywords = self._extract_tech_keywords(data)
        for tech in tech_keywords[:10]:
            content += f"- {tech}\n"
        
        content += """
## ğŸ¯ ã‚µãƒãƒ¼ãƒˆãƒã‚¤ãƒ³ãƒˆ

### ã‚ˆãã‚ã‚‹è³ªå•ãƒ†ãƒ¼ãƒ
"""
        # è³ªå•ã®å‚¾å‘ã‚’åˆ†æ
        question_themes = self._analyze_question_themes(data["questions"])
        for theme in question_themes[:5]:
            content += f"- {theme}\n"
        
        content += """
## ğŸ“ é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [æ´»å‹•å±¥æ­´](æ´»å‹•å±¥æ­´.md)
- [è³ªå•é›†](è³ªå•é›†.md)
- [é€²æ—è¨˜éŒ²](é€²æ—è¨˜éŒ².md)
- [æœˆå ±ä¸€è¦§](æœˆå ±/)

---
*æœ€çµ‚æ›´æ–°: """ + datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥") + "*"
        
        with open(overview_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info(f"ğŸ“‹ {member}_æ¦‚è¦.md ã‚’ä½œæˆ")
    
    def _create_activity_log(self, member: str, data: dict):
        """å…¨æ´»å‹•å±¥æ­´ã‚’1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«çµ±åˆ"""
        log_path = self.members_path / member / "æ´»å‹•å±¥æ­´.md"
        
        content = f"# {member} - æ´»å‹•å±¥æ­´\n\n"
        
        # ã™ã¹ã¦ã®æ´»å‹•ã‚’æ™‚ç³»åˆ—ã§ãƒãƒ¼ã‚¸
        all_activities = []
        
        for report in data["daily_reports"]:
            if isinstance(report, dict):
                all_activities.append({
                    "type": "æ—¥å ±",
                    "timestamp": report.get("timestamp", ""),
                    "content": report.get("content", ""),
                    "data": report
                })
        
        for question in data["questions"]:
            if isinstance(question, dict):
                all_activities.append({
                    "type": "è³ªå•",
                    "timestamp": question.get("timestamp", ""),
                    "content": question.get("content", ""),
                    "data": question
                })
        
        for progress in data["progress"]:
            if isinstance(progress, dict):
                all_activities.append({
                    "type": "é€²æ—",
                    "timestamp": progress.get("timestamp", ""),
                    "content": progress.get("content", ""),
                    "data": progress
                })
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã‚½ãƒ¼ãƒˆ
        all_activities.sort(key=lambda x: x["timestamp"], reverse=True)
        
        # æœˆã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        monthly_groups = {}
        for activity in all_activities:
            try:
                dt = datetime.fromisoformat(activity["timestamp"].replace('Z', '+00:00'))
                month_key = dt.strftime("%Yå¹´%mæœˆ")
                
                if month_key not in monthly_groups:
                    monthly_groups[month_key] = []
                monthly_groups[month_key].append(activity)
            except:
                pass
        
        # æœˆã”ã¨ã«å‡ºåŠ›
        for month, activities in sorted(monthly_groups.items(), reverse=True):
            content += f"## {month}\n\n"
            
            for activity in activities:
                try:
                    dt = datetime.fromisoformat(activity["timestamp"].replace('Z', '+00:00'))
                    date_str = dt.strftime("%m/%d")
                    time_str = dt.strftime("%H:%M")
                    
                    content += f"### {date_str} {time_str} - {activity['type']}\n\n"
                    
                    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ•´å½¢
                    activity_content = activity["content"]
                    if activity_content:
                        # é•·ã™ãã‚‹å ´åˆã¯è¦ç´„
                        if len(activity_content) > 500:
                            activity_content = activity_content[:500] + "..."
                        
                        content += activity_content + "\n\n"
                        
                        # é‡è¦ãªæ•°å€¤ã‚’æŠ½å‡º
                        numbers = self._extract_important_numbers(activity_content)
                        if numbers:
                            content += "**æ•°å€¤ãƒ‡ãƒ¼ã‚¿**: " + ", ".join(numbers) + "\n\n"
                    
                    content += "---\n\n"
                    
                except Exception as e:
                    logger.error(f"æ´»å‹•ãƒ­ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
        
        with open(log_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info(f"ğŸ“œ {member}/æ´»å‹•å±¥æ­´.md ã‚’ä½œæˆ")
    
    def _create_question_collection(self, member: str, questions: list):
        """è³ªå•é›†ã‚’ä½œæˆ"""
        questions_path = self.members_path / member / "è³ªå•é›†.md"
        
        content = f"# {member} - è³ªå•é›†\n\n"
        content += "ã“ã‚Œã¾ã§ã®è³ªå•ã¨ãã®è§£æ±ºçŠ¶æ³ã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚\n\n"
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«åˆ†é¡
        categorized = {
            "æŠ€è¡“": [],
            "å–¶æ¥­": [],
            "æ¡ˆä»¶": [],
            "ãã®ä»–": []
        }
        
        for q in questions:
            if isinstance(q, dict):
                q_content = q.get("content", "").lower()
                
                if any(word in q_content for word in ["å®Ÿè£…", "ã‚¨ãƒ©ãƒ¼", "ã‚³ãƒ¼ãƒ‰", "css", "javascript"]):
                    categorized["æŠ€è¡“"].append(q)
                elif any(word in q_content for word in ["å–¶æ¥­", "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ", "æ¡ˆä»¶ç²å¾—"]):
                    categorized["å–¶æ¥­"].append(q)
                elif any(word in q_content for word in ["ç´æœŸ", "æ¡ˆä»¶", "å¯¾å¿œ"]):
                    categorized["æ¡ˆä»¶"].append(q)
                else:
                    categorized["ãã®ä»–"].append(q)
        
        # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«å‡ºåŠ›
        for category, items in categorized.items():
            if items:
                content += f"## {category}é–¢é€£ï¼ˆ{len(items)}ä»¶ï¼‰\n\n"
                
                for i, q in enumerate(items[:20], 1):  # å„ã‚«ãƒ†ã‚´ãƒªæœ€å¤§20ä»¶
                    try:
                        dt = datetime.fromisoformat(q["timestamp"].replace('Z', '+00:00'))
                        date_str = dt.strftime("%Y/%m/%d")
                        
                        content += f"### {i}. {date_str}\n\n"
                        
                        q_content = q.get("content", "")
                        if len(q_content) > 300:
                            q_content = q_content[:300] + "..."
                        
                        content += f"{q_content}\n\n"
                        
                        # è§£æ±ºçŠ¶æ…‹
                        status = q.get("status", "open")
                        if status == "open":
                            content += "**çŠ¶æ…‹**: ğŸ”µ æœªè§£æ±º\n\n"
                        else:
                            content += "**çŠ¶æ…‹**: âœ… è§£æ±ºæ¸ˆã¿\n\n"
                        
                    except:
                        pass
                
                content += "---\n\n"
        
        with open(questions_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info(f"â“ {member}/è³ªå•é›†.md ã‚’ä½œæˆ")
    
    def _create_progress_log(self, member: str, progress_list: list):
        """é€²æ—è¨˜éŒ²ã‚’ä½œæˆ"""
        progress_path = self.members_path / member / "é€²æ—è¨˜éŒ².md"
        
        content = f"# {member} - é€²æ—è¨˜éŒ²\n\n"
        content += "å®Œäº†ã—ãŸä½œæ¥­ã¨æˆæœã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚\n\n"
        
        # æœˆã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        monthly_progress = {}
        
        for p in progress_list:
            if isinstance(p, dict):
                try:
                    dt = datetime.fromisoformat(p["timestamp"].replace('Z', '+00:00'))
                    month_key = dt.strftime("%Yå¹´%mæœˆ")
                    
                    if month_key not in monthly_progress:
                        monthly_progress[month_key] = []
                    monthly_progress[month_key].append(p)
                except:
                    pass
        
        # æœˆã”ã¨ã«å‡ºåŠ›
        for month, items in sorted(monthly_progress.items(), reverse=True):
            content += f"## {month}\n\n"
            
            for p in items:
                try:
                    dt = datetime.fromisoformat(p["timestamp"].replace('Z', '+00:00'))
                    date_str = dt.strftime("%m/%d")
                    
                    content += f"### {date_str}\n\n"
                    
                    p_content = p.get("content", "")
                    if p_content:
                        content += p_content + "\n\n"
                    
                except:
                    pass
            
            content += "---\n\n"
        
        with open(progress_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info(f"âœ… {member}/é€²æ—è¨˜éŒ².md ã‚’ä½œæˆ")
    
    def _consolidate_existing_files(self):
        """æ—¢å­˜ã®åˆ†æ•£ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµ±åˆ"""
        # yukari_webãƒ•ã‚©ãƒ«ãƒ€ã®å†…å®¹ã‚’yukariã«ç§»å‹•
        yukari_web_path = self.members_path / "yukari_web"
        yukari_path = self.members_path / "yukari"
        
        if yukari_web_path.exists():
            # æœˆå ±ã‚’ç§»å‹•
            if (yukari_web_path / "æœˆå ±").exists():
                for file in (yukari_web_path / "æœˆå ±").glob("*.md"):
                    target_dir = yukari_path / "æœˆå ±"
                    target_dir.mkdir(exist_ok=True)
                    shutil.copy2(file, target_dir / file.name)
                    logger.info(f"ğŸ“‹ {file.name} ã‚’yukariãƒ•ã‚©ãƒ«ãƒ€ã«çµ±åˆ")
            
            # yukari_webãƒ•ã‚©ãƒ«ãƒ€ã‚’å‰Šé™¤
            shutil.rmtree(yukari_web_path)
            logger.info("ğŸ—‘ï¸  yukari_webãƒ•ã‚©ãƒ«ãƒ€ã‚’å‰Šé™¤")
        
        # æ—¥ä»˜åˆ¥ãƒ•ã‚©ãƒ«ãƒ€ã‚’çµ±åˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        for member_dir in self.members_path.iterdir():
            if (member_dir.is_dir() and 
                member_dir.name not in self.exclude_members and 
                "gussan" not in member_dir.name.lower()):
                self._cleanup_date_folders(member_dir)
    
    def _cleanup_date_folders(self, member_dir: Path):
        """æ—¥ä»˜åˆ¥ãƒ•ã‚©ãƒ«ãƒ€ã‚’çµ±åˆ"""
        # gussanãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚Œã°å‰Šé™¤
        if member_dir.name in ["gussan", "gussan_yoshinani"] or "gussan" in member_dir.name.lower():
            shutil.rmtree(member_dir)
            logger.info(f"ğŸ—‘ï¸  {member_dir.name}ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‰Šé™¤")
            return
        
        # æ—¥å ±ã€è³ªå•å±¥æ­´ã€é€²æ—å ±å‘Šãªã©ã®æ—¥ä»˜åˆ¥ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç¢ºèª
        date_pattern = re.compile(r'\d{4}-\d{2}-\d{2}')
        
        for subfolder in member_dir.iterdir():
            if subfolder.is_dir() and date_pattern.match(subfolder.name):
                # æ—¥ä»˜ãƒ•ã‚©ãƒ«ãƒ€ã®å†…å®¹ã‚’è¦ªãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•
                for file in subfolder.glob("*"):
                    target = member_dir / file.name
                    if not target.exists():
                        shutil.move(str(file), str(target))
                
                # ç©ºã®æ—¥ä»˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‰Šé™¤
                if not list(subfolder.iterdir()):
                    subfolder.rmdir()
                    logger.info(f"ğŸ—‘ï¸  {subfolder.name} ã‚’å‰Šé™¤")
    
    def _extract_recent_activities(self, data: dict) -> list:
        """æœ€è¿‘ã®æ´»å‹•ã‚’æŠ½å‡º"""
        activities = []
        
        # æœ€æ–°ã®æ—¥å ±ã‹ã‚‰
        for report in data["daily_reports"][-5:]:
            if isinstance(report, dict):
                content = report.get("content", "")
                # æœ€åˆã®æ„å‘³ã®ã‚ã‚‹è¡Œã‚’æŠ½å‡º
                lines = content.split('\n')
                for line in lines:
                    if line.strip() and len(line) > 10:
                        activities.append(line.strip()[:100])
                        break
        
        return activities
    
    def _extract_tech_keywords(self, data: dict) -> list:
        """æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        tech_keywords = set()
        tech_list = [
            "HTML", "CSS", "JavaScript", "TypeScript", "React", "Vue", "Next.js",
            "WordPress", "PHP", "Python", "Git", "GitHub", "Figma", "AI", "ChatGPT"
        ]
        
        # ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œç´¢
        all_text = ""
        for category in data.values():
            for item in category:
                if isinstance(item, dict):
                    all_text += item.get("content", "") + " "
        
        all_text_lower = all_text.lower()
        for tech in tech_list:
            if tech.lower() in all_text_lower:
                tech_keywords.add(tech)
        
        return sorted(list(tech_keywords))
    
    def _analyze_question_themes(self, questions: list) -> list:
        """è³ªå•ã®ãƒ†ãƒ¼ãƒã‚’åˆ†æ"""
        themes = []
        theme_counts = {}
        
        theme_keywords = {
            "å®Ÿè£…ãƒ»ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°": ["å®Ÿè£…", "ã‚³ãƒ¼ãƒ‰", "ã‚¨ãƒ©ãƒ¼", "å‹•ä½œ", "æ›¸ãæ–¹"],
            "ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ»UI": ["ãƒ‡ã‚¶ã‚¤ãƒ³", "figma", "ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ", "css"],
            "å–¶æ¥­ãƒ»ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå¯¾å¿œ": ["å–¶æ¥­", "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ", "ææ¡ˆ", "è¿”ä¿¡"],
            "WordPressé–¢é€£": ["wordpress", "wp", "ãƒ—ãƒ©ã‚°ã‚¤ãƒ³"],
            "Gitãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†": ["git", "github", "ã‚³ãƒŸãƒƒãƒˆ", "ãƒ—ãƒƒã‚·ãƒ¥"],
            "AIæ´»ç”¨": ["ai", "chatgpt", "gpt", "claude"]
        }
        
        for q in questions:
            if isinstance(q, dict):
                content = q.get("content", "").lower()
                for theme, keywords in theme_keywords.items():
                    if any(keyword in content for keyword in keywords):
                        theme_counts[theme] = theme_counts.get(theme, 0) + 1
        
        # å¤šã„é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_themes = sorted(theme_counts.items(), key=lambda x: x[1], reverse=True)
        return [f"{theme}ï¼ˆ{count}ä»¶ï¼‰" for theme, count in sorted_themes]
    
    def _extract_important_numbers(self, content: str) -> list:
        """é‡è¦ãªæ•°å€¤ã‚’æŠ½å‡º"""
        numbers = []
        
        # æ™‚é–“
        time_matches = re.findall(r'(\d+\.?\d*)\s*æ™‚é–“', content)
        for match in time_matches:
            numbers.append(f"{match}æ™‚é–“")
        
        # ä»¶æ•°
        count_matches = re.findall(r'(\d+)\s*ä»¶', content)
        for match in count_matches:
            numbers.append(f"{match}ä»¶")
        
        # é‡‘é¡
        money_matches = re.findall(r'(\d+(?:,\d{3})*)\s*å††', content)
        for match in money_matches:
            numbers.append(f"{match}å††")
        
        return numbers[:5]  # æœ€å¤§5å€‹
    
    def _generate_consolidated_reports(self):
        """çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        summary_path = self.support_path / "ãƒ¡ãƒ³ãƒãƒ¼ç®¡ç†ã‚µãƒãƒªãƒ¼.md"
        
        content = """# ã‚°ãƒƒã‚µãƒãƒ»ãƒ©ãƒœ ãƒ¡ãƒ³ãƒãƒ¼ç®¡ç†ã‚µãƒãƒªãƒ¼

## ğŸ“Š æ¦‚è¦

ã“ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ã¯ã€ã‚°ãƒƒã‚µãƒãƒ»ãƒ©ãƒœã®ãƒ¡ãƒ³ãƒãƒ¼ï¼ˆgussanã‚’é™¤ãï¼‰ã®æ´»å‹•è¨˜éŒ²ãŒæ•´ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚

## ğŸ‘¥ ãƒ¡ãƒ³ãƒãƒ¼ä¸€è¦§

### [yukari](ãƒ¡ãƒ³ãƒãƒ¼ç®¡ç†/yukari/yukari_æ¦‚è¦.md)
- Webåˆ¶ä½œãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹
- ä¸»ãªæ´»å‹•: å–¶æ¥­æ´»å‹•ã€æ¡ˆä»¶å¯¾å¿œã€æŠ€è¡“å­¦ç¿’

### [ãƒ­ã‚°ã‚¸](ãƒ¡ãƒ³ãƒãƒ¼ç®¡ç†/ãƒ­ã‚°ã‚¸/ãƒ­ã‚°ã‚¸_æ¦‚è¦.md)
- å…ƒè£½é€ æ¥­ã‹ã‚‰Webåˆ¶ä½œã¸è»¢å‘
- ä¸»ãªæ´»å‹•: ç©æ¥µçš„ãªå–¶æ¥­æ´»å‹•ã€AIæ´»ç”¨ã®ç ”ç©¶

### [ã‚¿ã‚«ãƒãƒª](ãƒ¡ãƒ³ãƒãƒ¼ç®¡ç†/ã‚¿ã‚«ãƒãƒª/ã‚¿ã‚«ãƒãƒª_æ¦‚è¦.md)
- Webåˆ¶ä½œè€…
- ä¸»ãªæ´»å‹•: æ¡ˆä»¶å¯¾å¿œã€æŠ€è¡“å‘ä¸Š

## ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆ

```
ãƒ¡ãƒ³ãƒãƒ¼ç®¡ç†/
â”œâ”€â”€ yukari/
â”‚   â”œâ”€â”€ yukari_æ¦‚è¦.md      # ãƒ¡ãƒ³ãƒãƒ¼æ¦‚è¦
â”‚   â”œâ”€â”€ æ´»å‹•å±¥æ­´.md         # å…¨æ´»å‹•ã®æ™‚ç³»åˆ—è¨˜éŒ²
â”‚   â”œâ”€â”€ è³ªå•é›†.md           # è³ªå•ã¨å›ç­”ã®é›†ç´„
â”‚   â”œâ”€â”€ é€²æ—è¨˜éŒ².md         # å®Œäº†ã‚¿ã‚¹ã‚¯ã¨æˆæœ
â”‚   â””â”€â”€ æœˆå ±/               # æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆ
â”œâ”€â”€ ãƒ­ã‚°ã‚¸/
â”‚   â””â”€â”€ ï¼ˆåŒæ§˜ã®æ§‹æˆï¼‰
â””â”€â”€ ã‚¿ã‚«ãƒãƒª/
    â””â”€â”€ ï¼ˆåŒæ§˜ã®æ§‹æˆï¼‰
```

## ğŸ”„ æ›´æ–°æ–¹æ³•

1. Discordé€£æºã§æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
2. `venv/bin/python consolidate_members.py` ã‚’å®Ÿè¡Œ
3. æœˆå ±ã¯ `venv/bin/python monthly_report_analyzer.py` ã§ç”Ÿæˆ

---
*æœ€çµ‚æ›´æ–°: """ + datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥") + "*"
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info("ğŸ“Š ãƒ¡ãƒ³ãƒãƒ¼ç®¡ç†ã‚µãƒãƒªãƒ¼.md ã‚’ä½œæˆ")

if __name__ == "__main__":
    consolidator = MemberConsolidator()
    consolidator.consolidate_all_members()